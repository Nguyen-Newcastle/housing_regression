{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nguyen-Newcastle/housing_regression/blob/main/House_Price_Advanced_Regression_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hello everyone and welcome to my notebook about Housing Price Prediction. Housing Price Prediction is one of the typical Regression problem that every Machine Learning or Deep Learning practitioners must have encountered at least once in their life, especially those who are begineers in this field. Machine Learning and Deep Learning algorithms are generally considered the best techniques that you can utilized to get accurate House Price predictions. In this notebook I will download a Kaggle dataset that contains informations about House Price in a region in the United States. The dataset is fairly small if compared to real-life dataset(training set just has 1000 samples), but that must be enough for amateurs like us.**"
      ],
      "metadata": {
        "id": "U6K3g5IIXmW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First I install the library keras_tuner into our working environment. This is a library used in the hyperparameter tuning process of Deep Learning models, to help developers to find the combinations of hyperparameters that yield the best result. But first I will apply regular Machine Learning algorithm first, so let leave it here for use later.**"
      ],
      "metadata": {
        "id": "Di5ykRFLW6-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBOJPWBy32W0",
        "outputId": "7c2d5bd8-c7d1-4e97-d62d-8e9999e5aee3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/176.1 kB\u001b[0m \u001b[31m954.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m122.9/176.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Belows is the preparatory code to check various configuration in the virtual environment. We check the version of tensorflow, scikit-learn and keras libraries and creating directory for storing images(if there is any). Finally we create a function to save the figures. Actually this is the piece of code I borrow from Aurelien Geron in his monumental introductory book for Machine Learning practitioners \"Hand-on Machine Learning\".**"
      ],
      "metadata": {
        "id": "_acnD6mIZnNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HlNbt3YETS7C"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "from tensorflow import keras\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. RNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "#Importing libraries needed\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = os.getcwd()\n",
        "CHAPTER_ID = \"house_price_advanced_regression\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "#Function to save the figures, if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ueqJgTE9YYPg"
      },
      "outputs": [],
      "source": [
        "#Import Zipfile to extract the zip file that contain the dataset.\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I store my dataset, which is now condensed in a Zip file, in a GitHub repository. Here I pull the repository to the current working environment using the familiar command git clone.**"
      ],
      "metadata": {
        "id": "zUE8NAKNadWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nguyen-Newcastle/housing_regression.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaWtr837ryKz",
        "outputId": "a0b8d9a5-f353-4a20-8507-47317faeea0e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'housing_regression'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (6/6), 200.28 KiB | 50.07 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The folder that contain the Zip file.\n",
        "DATASET_ROOT_DIR = os.path.join(PROJECT_ROOT_DIR, \"housing_regression\")"
      ],
      "metadata": {
        "id": "lW7GNLx1uAUw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below we have a view at which files are stored in the Zip file. There are a txt file for data description, a sample csv file for submission of test data prediction, and most importantly, a csv file containing train data and the other for test data.**"
      ],
      "metadata": {
        "id": "8syXVg9Ka69l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwiVTMi9YlYj",
        "outputId": "f4aad533-a4f1-4313-f2fd-40ee4a5715b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_description.txt', 'sample_submission.csv', 'test.csv', 'train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Constructing the path to the zipfile containing the dataset. In here we list all the files inside the zip archive.\n",
        "HOUSING_ZIPFILE_PATH = zipfile.ZipFile(os.path.join(DATASET_ROOT_DIR,'house-prices-advanced-regression-techniques.zip'))\n",
        "HOUSING_ZIPFILE_PATH.namelist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TKKz0utUdfS1"
      },
      "outputs": [],
      "source": [
        "HOUSING_ZIPFILE_PATH = os.path.join(DATASET_ROOT_DIR,'house-prices-advanced-regression-techniques.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2R3gy0CccvlV"
      },
      "outputs": [],
      "source": [
        "#Creating a location to extract the zipfile.\n",
        "HOUSING_DATASET_DIRECTORY = os.path.join(DATASET_ROOT_DIR, 'dataset')\n",
        "os.makedirs(HOUSING_DATASET_DIRECTORY, exist_ok = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to extract Zip file to specified location.**"
      ],
      "metadata": {
        "id": "g6qeCbW8bYY0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "U6rFgp6JaOW6"
      },
      "outputs": [],
      "source": [
        "def extracting_zip_file(zipfile_directory = HOUSING_ZIPFILE_PATH, where_to_extract = HOUSING_DATASET_DIRECTORY):\n",
        "    with zipfile.ZipFile(HOUSING_ZIPFILE_PATH, \"r\") as path:\n",
        "          path.extractall(where_to_extract)\n",
        "          path.close()\n",
        "#A function to extract all files inside a zip file. This function is used to extract everything from the zipfile to a specified location(in this case,\n",
        "#the directory \"DATASET_ROOT_DIR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Zip file**"
      ],
      "metadata": {
        "id": "pyBq7pqdbfMS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "C4uxodAlbKpx"
      },
      "outputs": [],
      "source": [
        "extracting_zip_file() #EXTRACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function for reading housing data from csv file into a pandas DataFrame.**"
      ],
      "metadata": {
        "id": "lUT7q4ENb0H0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VRbkJBXHduGi"
      },
      "outputs": [],
      "source": [
        "def reading_housing_data(directory = os.path.join(HOUSING_DATASET_DIRECTORY,\"train.csv\")):\n",
        "    return pd.read_csv(directory)\n",
        "#Function to return a DataFrame about housing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dydfjJTjeNYp"
      },
      "source": [
        "**Now what we are going to do is reading the training dataset and try to get the general information about the data we have, in order to prepare for subsequent training using Machine Learning. First I am going to use scikit-learn to train Machine Learning model, without using neural networks.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "xqX-0uzad_BP",
        "outputId": "74286852-c92c-4e73-bfa2-9d7f2f3bc224"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
              "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
              "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
              "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
              "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
              "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
              "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
              "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
              "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
              "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
              "\n",
              "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0         2   2008        WD         Normal     208500  \n",
              "1         5   2007        WD         Normal     181500  \n",
              "2         9   2008        WD         Normal     223500  \n",
              "3         2   2006        WD        Abnorml     140000  \n",
              "4        12   2008        WD         Normal     250000  \n",
              "...     ...    ...       ...            ...        ...  \n",
              "1455      8   2007        WD         Normal     175000  \n",
              "1456      2   2010        WD         Normal     210000  \n",
              "1457      5   2010        WD         Normal     266500  \n",
              "1458      4   2010        WD         Normal     142125  \n",
              "1459      6   2008        WD         Normal     147500  \n",
              "\n",
              "[1460 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a3a3860-a13e-4418-8e18-2f68a5ee2618\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GdPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a3a3860-a13e-4418-8e18-2f68a5ee2618')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a3a3860-a13e-4418-8e18-2f68a5ee2618 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a3a3860-a13e-4418-8e18-2f68a5ee2618');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3fb94d1f-4686-4f39-8659-a8508ba8440b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fb94d1f-4686-4f39-8659-a8508ba8440b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3fb94d1f-4686-4f39-8659-a8508ba8440b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_dataframe = reading_housing_data()\n",
        "train_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below we use the function info() to get some basic information about our training set. There are 1460 samples in the train set. You can see that there are numerical columns with missing values, but none of these numerical columns has so many missing values, so I won't drop any of the numerical columns. For categorical columns, there are many of them which contain mostly NaN values, but I still decide to keep all of them in the preprocessing step.**"
      ],
      "metadata": {
        "id": "j89PeLIAlQ4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataframe.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCWYbjhqlCHR",
        "outputId": "f624fd0e-980f-4a15-b1ef-7613d63df596"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 80 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            "dtypes: float64(3), int64(34), object(43)\n",
            "memory usage: 912.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of the target column \"SalePrice\" in the training set. You can clearly see that the housing prices mainly concentrate around the range 100000-to-200000.**"
      ],
      "metadata": {
        "id": "Y5CS3DGgknu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "OQDVE-cuiom7",
        "outputId": "26ca53f7-001a-4703-f079-805e0609380c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving figure SalePrice_distribution\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "train_dataframe['SalePrice'].hist(bins = 50)\n",
        "plt.title(\"Distribution of SalePrice in the training set.\")\n",
        "plt.xlabel(\"SalePrice\", fontsize = 14)\n",
        "plt.ylabel(\"Number of occurrences\", fontsize = 14)\n",
        "save_fig(\"SalePrice_distribution\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For each categorical columns, I calculate the number of unique categories within each column. In here you can see that we got so many categorical columns in the dataset, but the number of categories in each column is not so much. Most of them have only around less than 10 unique categories. So the conclusion is that, later in the preprocessing step we can perform one-hot-encoding on categorical columns.**"
      ],
      "metadata": {
        "id": "UQl_LEkBjQd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iR2u7bx6TyhB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99ec3351-9451-4faa-c97a-cf40dd3893a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Unique_Values\n",
              "MSZoning                   5\n",
              "Street                     2\n",
              "Alley                      3\n",
              "LotShape                   4\n",
              "LandContour                4\n",
              "Utilities                  2\n",
              "LotConfig                  5\n",
              "LandSlope                  3\n",
              "Neighborhood              25\n",
              "Condition1                 9\n",
              "Condition2                 8\n",
              "BldgType                   5\n",
              "HouseStyle                 8\n",
              "RoofStyle                  6\n",
              "RoofMatl                   8\n",
              "Exterior1st               15\n",
              "Exterior2nd               16\n",
              "MasVnrType                 5\n",
              "ExterQual                  4\n",
              "ExterCond                  5\n",
              "Foundation                 6\n",
              "BsmtQual                   5\n",
              "BsmtCond                   5\n",
              "BsmtExposure               5\n",
              "BsmtFinType1               7\n",
              "BsmtFinType2               7\n",
              "Heating                    6\n",
              "HeatingQC                  5\n",
              "CentralAir                 2\n",
              "Electrical                 6\n",
              "KitchenQual                4\n",
              "Functional                 7\n",
              "FireplaceQu                6\n",
              "GarageType                 7\n",
              "GarageFinish               4\n",
              "GarageQual                 6\n",
              "GarageCond                 6\n",
              "PavedDrive                 3\n",
              "PoolQC                     4\n",
              "Fence                      5\n",
              "MiscFeature                5\n",
              "SaleType                   9\n",
              "SaleCondition              6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50e8cf66-7c0f-43ae-a511-364b470ec6be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unique_Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSZoning</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Street</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alley</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotShape</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LandContour</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Utilities</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LotConfig</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LandSlope</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Neighborhood</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Condition1</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Condition2</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BldgType</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HouseStyle</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RoofStyle</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RoofMatl</th>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exterior1st</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exterior2nd</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MasVnrType</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExterQual</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ExterCond</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Foundation</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtQual</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtCond</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtExposure</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Heating</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeatingQC</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CentralAir</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Electrical</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KitchenQual</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Functional</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FireplaceQu</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageType</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageFinish</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageQual</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GarageCond</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PavedDrive</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PoolQC</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fence</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MiscFeature</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleType</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SaleCondition</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50e8cf66-7c0f-43ae-a511-364b470ec6be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50e8cf66-7c0f-43ae-a511-364b470ec6be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50e8cf66-7c0f-43ae-a511-364b470ec6be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78533aee-7f63-421a-bdbc-3167783b4acc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78533aee-7f63-421a-bdbc-3167783b4acc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78533aee-7f63-421a-bdbc-3167783b4acc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "category_column_names = list(train_dataframe.select_dtypes(include = ['object']).columns)\n",
        "num_unique_values = []\n",
        "for column_names in category_column_names:\n",
        "    num_unique = len(pd.unique(train_dataframe[column_names]))\n",
        "    num_unique_values.append(num_unique)\n",
        "pd.DataFrame({\"Unique_Values\": num_unique_values}, index = category_column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You can see here we got 38 numerical columns(including the target column \"SalePrice\"). Obviously we don't need the column name \"Id\" in our final training dataset, so we will drop it in the preprocessing step.**"
      ],
      "metadata": {
        "id": "Ypr5dw2tkIHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "jrDfYdWiaPQm",
        "outputId": "61e96329-b9d8-4cc9-94c9-ea0960f9fb03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
              "0        1          60         65.0     8450            7            5   \n",
              "1        2          20         80.0     9600            6            8   \n",
              "2        3          60         68.0    11250            7            5   \n",
              "3        4          70         60.0     9550            7            5   \n",
              "4        5          60         84.0    14260            8            5   \n",
              "...    ...         ...          ...      ...          ...          ...   \n",
              "1455  1456          60         62.0     7917            6            5   \n",
              "1456  1457          20         85.0    13175            6            6   \n",
              "1457  1458          70         66.0     9042            7            9   \n",
              "1458  1459          20         68.0     9717            5            6   \n",
              "1459  1460          20         75.0     9937            5            6   \n",
              "\n",
              "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  \\\n",
              "0          2003          2003       196.0         706  ...           0   \n",
              "1          1976          1976         0.0         978  ...         298   \n",
              "2          2001          2002       162.0         486  ...           0   \n",
              "3          1915          1970         0.0         216  ...           0   \n",
              "4          2000          2000       350.0         655  ...         192   \n",
              "...         ...           ...         ...         ...  ...         ...   \n",
              "1455       1999          2000         0.0           0  ...           0   \n",
              "1456       1978          1988       119.0         790  ...         349   \n",
              "1457       1941          2006         0.0         275  ...           0   \n",
              "1458       1950          1996         0.0          49  ...         366   \n",
              "1459       1965          1965         0.0         830  ...         736   \n",
              "\n",
              "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
              "0              61              0          0            0         0        0   \n",
              "1               0              0          0            0         0        0   \n",
              "2              42              0          0            0         0        0   \n",
              "3              35            272          0            0         0        0   \n",
              "4              84              0          0            0         0        0   \n",
              "...           ...            ...        ...          ...       ...      ...   \n",
              "1455           40              0          0            0         0        0   \n",
              "1456            0              0          0            0         0        0   \n",
              "1457           60              0          0            0         0     2500   \n",
              "1458            0            112          0            0         0        0   \n",
              "1459           68              0          0            0         0        0   \n",
              "\n",
              "      MoSold  YrSold  SalePrice  \n",
              "0          2    2008     208500  \n",
              "1          5    2007     181500  \n",
              "2          9    2008     223500  \n",
              "3          2    2006     140000  \n",
              "4         12    2008     250000  \n",
              "...      ...     ...        ...  \n",
              "1455       8    2007     175000  \n",
              "1456       2    2010     210000  \n",
              "1457       5    2010     266500  \n",
              "1458       4    2010     142125  \n",
              "1459       6    2008     147500  \n",
              "\n",
              "[1460 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eef6d7d-cf98-4298-bb8b-9c575c2792b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>...</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>119.0</td>\n",
              "      <td>790</td>\n",
              "      <td>...</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>...</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>830</td>\n",
              "      <td>...</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows × 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eef6d7d-cf98-4298-bb8b-9c575c2792b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8eef6d7d-cf98-4298-bb8b-9c575c2792b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8eef6d7d-cf98-4298-bb8b-9c575c2792b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6bb3eef7-7679-4af0-b381-bb3d9624fbc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bb3eef7-7679-4af0-b381-bb3d9624fbc1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6bb3eef7-7679-4af0-b381-bb3d9624fbc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_dataframe.select_dtypes(include = ['int64', 'float64'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Later on we must preprocess the original dataframe in order to get the dataset ready to be fed into Machine Learning algorithm, so I build this class to drop columns I don't want to be included. So I build this class, which inherit scikit-learn Base Class for all estimators in scikit-learn. The transform() function would take a list of column names I want to drop and then would drop columns with those names. Later I will pass this class into scikit-learn preprocessing pipeline.**"
      ],
      "metadata": {
        "id": "IL3cuYY4S104"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lbaF1IWJl561"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Drop_Column(BaseEstimator, TransformerMixin):\n",
        "      def __init__(self, drop_column = [\"Id\"]):\n",
        "          self.drop_column = drop_column\n",
        "      def fit(self, X, y = None):\n",
        "          return self\n",
        "      def transform(self, X):\n",
        "          data = X.copy()\n",
        "          if self.drop_column is not None:\n",
        "              data = data.drop(labels = self.drop_column,axis = 1)\n",
        "          return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1vS-3KQlnlYC"
      },
      "outputs": [],
      "source": [
        "train_labels = train_dataframe[\"SalePrice\"].copy()\n",
        "train_dataframe.drop(\"SalePrice\", axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsOWrxUHn0uH"
      },
      "source": [
        "**In this stage we will build the pipeline to preprocess the train dataframe, making it ready to be fed into Machine Learning model. Scikit Learn offer many really useful, easy-to-use functions for us to do. Our data would go through two separate pipelines, one piepline is reserved for numerical columns and the other pipeline is for categorical data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hsRAp3y_p-3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HScEH1VCqCXJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_selector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIBPaVy-ob_S"
      },
      "source": [
        "**For numerical columns, we would fill columns which have null values with the median value of that particular column. We do that because all numerical columns have fairly adequate data and the amount of missing data is fairly small. If there are columns which contain mostly null values, we probably have to drop it, but that's not the case at least for this dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KjtG-MKPqhMB"
      },
      "outputs": [],
      "source": [
        "num_pipeline = Pipeline([(\"imputer\",SimpleImputer(strategy = \"median\")),\n",
        "                        (\"std_scaler\",StandardScaler())])\n",
        "#Pipeline to transform numerical column. First we fill missing values with the median value of the respective column,\n",
        "#then we standardize the data so that all columns will have the same scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p10OCCCGpHxC"
      },
      "source": [
        "**For categorical columns, we will do One-Hot Encoder, by that each column will be separated into multiple columns equal to the number of unique values in that column. By this technique, we would add hundred more features to our dataset, simply because the number of categorical columns and the number of categories for each categorical column is relatively large. In particular, we have the resulting dataset of about more than 200 features after going through full pipeline.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yzOpaJWrqkO8"
      },
      "outputs": [],
      "source": [
        "cat_pipeline = Pipeline([(\"ordinal_encoder\",\n",
        "                          OneHotEncoder(handle_unknown = \"infrequent_if_exist\", min_frequency = 10))])\n",
        "#For categorical columns, we use OneHotEncoder to transform the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ColumnTransformer() function will separate the data into 2 different subset(numerical and categorical subset) and then apply different preprocessing pipelines for each of them. After getting the transformed subsets of both numerical and categorical ones, the 2 subsets will be concatenated into 1, ready for ML algorithm.**"
      ],
      "metadata": {
        "id": "3v2axvG5m-bq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "00pbDsVMrX5r"
      },
      "outputs": [],
      "source": [
        "col_transform = ColumnTransformer(transformers = [\n",
        "    (\"num_pipeline\", num_pipeline,make_column_selector(dtype_include = np.number)),\n",
        "    (\"cat_pipeline\", cat_pipeline,make_column_selector(dtype_include = object))\n",
        "],sparse_threshold = 0.0)\n",
        "#ColumnTransformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn5fPJd_qQKz"
      },
      "source": [
        "**Constructing the full pipeline and the dataframe would go through it.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2MZBzrxxrdmo"
      },
      "outputs": [],
      "source": [
        "full_pipeline = Pipeline([(\"drop_process\", Drop_Column()),\n",
        "                         (\"col_transform\", col_transform)])\n",
        "housing_prepared = full_pipeline.fit_transform(train_dataframe)\n",
        "#The training data will undergo multiple transformation pipelines and finally we are ready for some ML algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here you clearly see that the number of features has increased dramatically from 79 to 260.**"
      ],
      "metadata": {
        "id": "h8OT5sT1s2Ei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygHnc-hr1Cr",
        "outputId": "54e6c981-f1a8-40d1-9bf4-123507fd5a5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 260)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "housing_prepared.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The mean and median housing prices of the training dataset, just to give a look at the error we should be able to achieve.**"
      ],
      "metadata": {
        "id": "-FEjiKMNtBTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zME1GwhgsBJD",
        "outputId": "8b3439cc-3203-47c0-c840-6f9f69f83d39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180921.19589041095, 163000.0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_labels.mean(), train_labels.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja3Dz0P2m4iF"
      },
      "source": [
        "**Now it's time to train the dataset. We will try many ensemble of decision trees models to see which ones are the most appropriate for our tasks. In this stage the aim is just finding models which offer the most potential, so we wouldn't fine-tune the model by hyperparameters tuning, but instead we just use the default hyperparameters set by Scikit-Learn.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nQ2b0aSWsFVg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9piUwMZ5vX5X"
      },
      "source": [
        "**First we will experiment with RandomForestRegressor. First we fit the model with training data and training labels, we get the evaluation measured by Root-Mean Squared Error and then we would cross-validate the model to see how well it performs on average when facing with unseen validation data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWdJaI8Osb3Q",
        "outputId": "953e1895-ffea-4953-e4b0-0eee01b4532a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11019.250068620648"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "random_forest_regressor = RandomForestRegressor(random_state = 42)\n",
        "random_forest_regressor.fit(housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, random_forest_regressor.predict(housing_prepared), squared = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DDzwiJC6tmWP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "mean_squared = make_scorer(mean_squared_error, greater_is_better = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PSzwZSx9vCVL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaBhDhg5v3R6"
      },
      "source": [
        "**K-fold cross-validation, where we will divide the training data into 5 folds for cross validation and calculate the average results. Above we see that the training error is around 11000 but the cross-validation error is nearly 30000, so there must be overfitting occured.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXcvMN-btaSH",
        "outputId": "56998414-9a94-4afa-f153-8f65e868934b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29861.403387419374"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(random_forest_regressor, housing_prepared, train_labels, cv = 5,scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dpW2HI0wRpO"
      },
      "source": [
        "**Repeating the process for BaggingRegressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo9SpqK4xdB8",
        "outputId": "4e32ce21-43f0-4bee-def2-bf63a6774bc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11988.428927347184"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "bag_reg = BaggingRegressor(random_state = 42)\n",
        "bag_reg.fit(housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, bag_reg.predict(housing_prepared), squared = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwn5or8Qx0Jd",
        "outputId": "64fd40e7-72a3-4b2e-9823-e9214116ad94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30793.29629964789"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(bag_reg, housing_prepared, train_labels, cv = 5,scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtqDQAtNwYHI"
      },
      "source": [
        "**GradientBoostingRegressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ18H5JmyC8j",
        "outputId": "37c06ae9-c4b0-43a8-f78a-19b536ad7a3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14497.804987707143"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "grad_boost = GradientBoostingRegressor(random_state = 42)\n",
        "grad_boost.fit(housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, grad_boost.predict(housing_prepared), squared = False)\n",
        "#Fitting the data with GradientBoostingRegressor model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkVpSH2TwdXt"
      },
      "source": [
        "**The training error got bigger than the previous 2 models, but the cross-validation score becomes much better. Most promising model so far.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hveV_JcyyUQD",
        "outputId": "27af3385-8c2d-44c2-8353-995d92bc9485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26422.28767283751"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(grad_boost, housing_prepared, train_labels, cv = 5,scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD59mEHbwt1U"
      },
      "source": [
        "**Experimenting with SVR, dissapointing result.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2hqC8WQzXLN",
        "outputId": "89d79422-e46c-40cf-d5d3-a4b23a3bbfa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70748.70236768886"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "linear_svr = SVR(kernel = \"poly\", degree = 20)\n",
        "linear_svr.fit(housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, linear_svr.predict(housing_prepared), squared = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ExtraTreeRegressor, not so good either.**"
      ],
      "metadata": {
        "id": "WFBbJXJlsqVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93COdOj-qmEo",
        "outputId": "cc9f37f3-1ae2-4f05-f7b3-ca0e26e75680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14354.799595106932"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "extra_tree = ExtraTreesRegressor(random_state = 42, n_estimators = 175, max_samples = 0.75, bootstrap = True)\n",
        "extra_tree.fit(housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, extra_tree.predict(housing_prepared), squared = False)\n",
        "#Fitting the data with GradientBoostingRegressor model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNTpoe-vq2CM",
        "outputId": "b4bf7396-5f01-415f-ad57-57402950c307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30035.537049913255"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(extra_tree, housing_prepared, train_labels, cv = 5,scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the code below I try using a relativelt new Tree Ensemble Model to fit my training dataset that require me to build relatively different preprocessing pipeline to prepare the appropriate form of data required by the model. To prepare data for the model named Histogram-Based Gradient Boosting Regressor, categorical columns must be passed through OrdinalEncoding, so unlike OneHotEncoder, the number of features after preprocessing remained unchanged. When unseen categories being passed to the pipeline during inference time(that's when you feed new data for a deployed Machine Learning model to make prediction), the OrdinalEncoder here would return NaN, but luckily this algorithm has way to deal with missing value in features, which I won't go into detail here. Anyway, this Model requires me to build another pipeline, and the code below illustrates that.**"
      ],
      "metadata": {
        "id": "ZfzXroxRqhMJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "F0rNtpCg8oEr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal_cat_pipeline = Pipeline([(\"ordinal_encoder\",\n",
        "                          OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = np.NAN))])\n",
        "col_transform_2 = ColumnTransformer(transformers = [\n",
        "    (\"num_pipeline\", num_pipeline, make_column_selector(dtype_include = np.number)),\n",
        "    (\"cat_pipeline\", ordinal_cat_pipeline, make_column_selector(dtype_include = object))\n",
        "  ]\n",
        ")\n",
        "\n",
        "dropped_train_dataframe = Drop_Column().fit_transform(train_dataframe)\n",
        "category_columns = dropped_train_dataframe.select_dtypes(include=['object'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "IuFvTOcSAjvo"
      },
      "outputs": [],
      "source": [
        "full_pipeline_2 = Pipeline([(\"drop_process\", Drop_Column()),\n",
        "                         (\"col_transform\", col_transform_2)])\n",
        "housing_prepared_2 = full_pipeline_2.fit_transform(train_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As you can see the number of features remains 79 just like the original."
      ],
      "metadata": {
        "id": "JwFpbktEsOe1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L06xK_h4CfbZ",
        "outputId": "1f2e9f90-8a55-40df-e60c-c639131595d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 79)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "housing_prepared_2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAXdzm5xHsKp",
        "outputId": "b3a037b7-ef76-4822-d84e-3cfce433a546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10143.778365273081"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "category_columns_indices = [False for i in range(36)] + [True for i in range(36, 79)]\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "hist_grad_boost = HistGradientBoostingRegressor(random_state = 42, categorical_features = category_columns_indices)\n",
        "hist_grad_boost.fit(housing_prepared_2, train_labels)\n",
        "mean_squared_error(train_labels, hist_grad_boost.predict(housing_prepared_2), squared = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unfortunately for me the new Model doesn't work better than traditional GraidentBoostingRegressor, so I couldn't pick that Model for Hyperparameter tuning.**"
      ],
      "metadata": {
        "id": "kMmg0uW5sXc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtMOh3eIsYb",
        "outputId": "f7c7752f-125f-4481-8b06-0b32708eb16e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27615.86740870726"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(hist_grad_boost, housing_prepared_2, train_labels, cv = 5,scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtzJgWIhbuyt"
      },
      "source": [
        "**You can easily see that the number of features in the dataset used for fitting is overwhemingly large, more than 200 features. It is somewhat logical to conclude that many, if not most, of these features are not really important, which means that their contribution to the accuracy of the prediction are negligible. So you might think that we should drop unimportant features in the preprocessing step and leave only relatively relevant features left for fitting the ML model. But how are we going to know which features to be dropped. Well that is when the module sklearn.feature_selection comes into play. The module offer various feature selection algorithm for you to pick, in here I will pick the Recursive Features Elimination(RFE) algorithm. After being done with numerical and categorical preprocessing, we will add RFE to the preprocessing pipeline. We specify clearly that we want 100 features left in the dataset, and sklearn should take care of the rest.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "npBdsOklXEy7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "fea_select_pipeline = Pipeline([(\"full_pipeline\", full_pipeline),\n",
        "                         (\"fea_select_RFE\", RFE(estimator = DecisionTreeRegressor(), n_features_to_select = 150))\n",
        "])\n",
        "fea_select_housing_prepared = fea_select_pipeline.fit_transform(train_dataframe, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-h5DK3_a0tz",
        "outputId": "2ab80e86-bca6-43f0-fdd5-fc228fc32d34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14774.737747668054"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "fea_select_grad_boost = GradientBoostingRegressor(random_state = 42)\n",
        "fea_select_grad_boost.fit(fea_select_housing_prepared, train_labels)\n",
        "mean_squared_error(train_labels, fea_select_grad_boost.predict(fea_select_housing_prepared), squared = False)\n",
        "#Fitting the data with GradientBoostingRegressor model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After preprossing the data and perform feature selection, I tried to apply GradientBoostingRegressor algorithm to the dataset and see the result of cross-validation. Unfortunately the result I got was not better than when I retain full dataset without feature selection(in here, 26809 compared to 26422 for full dataset), so I decided feature selection is not worth it.**"
      ],
      "metadata": {
        "id": "TH8N45p3Rjx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvXCCfegbaG6",
        "outputId": "da1c537c-5a2f-4471-bbbf-8762fa6e8172"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27151.39283719883"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "cross_validation = np.abs(cross_val_score(fea_select_grad_boost, fea_select_housing_prepared, train_labels, cv = 5, scoring = mean_squared))\n",
        "np.mean(np.sqrt(cross_validation))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zos2U1TlxF07"
      },
      "source": [
        "**Now probably it's time for fine-tuning to see if we can improve on our seemingly promising model by changing the default parameters. GridSearchCV from Scikit-Learn is OK but it can be time-consuming, so in here I will use RandomizedSearchCV to fine-tune the models. It will randomly choose parameters as we mention, inside the possible range configured by us and train multiple models using those randomly chosen parameters to see which combinaion of paraemters would yield be best result.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "x8LmyxEu6SH7",
        "outputId": "92f66e42-e11e-484c-fd21-362d1baca44f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a46c7b50>,\n",
              "                                        'max_features': ['sqrt', None],\n",
              "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1d50>,\n",
              "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1ff0>,\n",
              "                                        'subsample': [0.75, 1.0]},\n",
              "                   random_state=42,\n",
              "                   scoring=make_scorer(mean_squared_error, greater_is_better=False))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a46c7b50&gt;,\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, None],\n",
              "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1d50&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1ff0&gt;,\n",
              "                                        &#x27;subsample&#x27;: [0.75, 1.0]},\n",
              "                   random_state=42,\n",
              "                   scoring=make_scorer(mean_squared_error, greater_is_better=False))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=42),\n",
              "                   n_iter=50,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a46c7b50&gt;,\n",
              "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, None],\n",
              "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1d50&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7978a3bb1ff0&gt;,\n",
              "                                        &#x27;subsample&#x27;: [0.75, 1.0]},\n",
              "                   random_state=42,\n",
              "                   scoring=make_scorer(mean_squared_error, greater_is_better=False))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "#the dictionary to specify the searching space for various hyperparameters of our best ML Model so far: \"Gradient Boosting Regressor\".\n",
        "grad_boost_params = {\n",
        "    \"n_estimators\": randint(low = 80, high = 220),\n",
        "    \"subsample\": [0.75, 1.0],\n",
        "    \"min_samples_split\": randint(low = 5, high = 25),\n",
        "    \"max_depth\": randint(low = 3, high = 10),\n",
        "    \"max_features\": [\"sqrt\", None]\n",
        "}\n",
        "grad_boost_rs = RandomizedSearchCV(grad_boost, param_distributions = grad_boost_params, n_iter = 50, cv = 5, scoring = mean_squared,\n",
        "                                   random_state = 42) #searching using cross-validation of 5 folds, with 50 different combination of hyperparameters\n",
        "grad_boost_rs.fit(housing_prepared, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below is the score of the best founded model. The average MSE on cross-validation is around 25000."
      ],
      "metadata": {
        "id": "10YMe7PAqQVy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWuErVrd6S27",
        "outputId": "362f8e79-7a59-4508-b66e-0fe706ce4c22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25358.040287246313"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "np.sqrt(-grad_boost_rs.best_score_)#best score of fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "UC0OnHVF6uWt",
        "outputId": "bb789c8d-0f22-4771-a4b1-f6c157183f9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=4, min_samples_split=17, n_estimators=141,\n",
              "                          random_state=42, subsample=0.75)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=4, min_samples_split=17, n_estimators=141,\n",
              "                          random_state=42, subsample=0.75)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=4, min_samples_split=17, n_estimators=141,\n",
              "                          random_state=42, subsample=0.75)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "grad_boost_rs.best_estimator_ #hyperparameters of the best estimator."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(grad_boost_rs.cv_results_)[[\"param_max_depth\", \"param_max_features\", \"param_min_samples_split\", \"param_n_estimators\",\n",
        "                                         \"rank_test_score\"]]"
      ],
      "metadata": {
        "id": "gCXgB0i2GlDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07706145-9317-4e82-c41b-8b0a1c3bacfe"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   param_max_depth param_max_features param_min_samples_split  \\\n",
              "0                9               None                      19   \n",
              "1                7               sqrt                      11   \n",
              "2                9               sqrt                      15   \n",
              "3                6               None                       7   \n",
              "4                6               None                      10   \n",
              "5                6               sqrt                       5   \n",
              "6                7               None                      21   \n",
              "7                4               None                      20   \n",
              "8                8               sqrt                      23   \n",
              "9                6               None                       7   \n",
              "10               7               sqrt                      11   \n",
              "11               3               None                      18   \n",
              "12               7               None                      24   \n",
              "13               6               sqrt                      16   \n",
              "14               5               None                      21   \n",
              "15               6               None                      10   \n",
              "16               6               None                      22   \n",
              "17               4               None                       8   \n",
              "18               9               None                      18   \n",
              "19               7               None                      19   \n",
              "20               4               sqrt                      17   \n",
              "21               9               sqrt                       5   \n",
              "22               3               None                       5   \n",
              "23               9               sqrt                      23   \n",
              "24               5               sqrt                       5   \n",
              "25               4               sqrt                      13   \n",
              "26               3               None                      16   \n",
              "27               9               sqrt                       9   \n",
              "28               8               sqrt                       7   \n",
              "29               8               sqrt                       5   \n",
              "30               9               sqrt                      18   \n",
              "31               3               sqrt                      19   \n",
              "32               6               sqrt                      23   \n",
              "33               9               sqrt                      24   \n",
              "34               8               sqrt                      11   \n",
              "35               7               None                      11   \n",
              "36               4               None                      17   \n",
              "37               7               None                      16   \n",
              "38               8               None                      15   \n",
              "39               9               None                      11   \n",
              "40               5               None                      24   \n",
              "41               8               None                      13   \n",
              "42               3               sqrt                      14   \n",
              "43               3               None                      21   \n",
              "44               4               None                      16   \n",
              "45               5               sqrt                       9   \n",
              "46               3               sqrt                      21   \n",
              "47               6               None                       9   \n",
              "48               8               None                      16   \n",
              "49               5               None                      21   \n",
              "\n",
              "   param_n_estimators  rank_test_score  \n",
              "0                 186               42  \n",
              "1                 201               20  \n",
              "2                 167               39  \n",
              "3                 132               41  \n",
              "4                 209               37  \n",
              "5                 137               33  \n",
              "6                 138               16  \n",
              "7                  94               15  \n",
              "8                 187               45  \n",
              "9                 130               14  \n",
              "10                 97               35  \n",
              "11                 88               25  \n",
              "12                171               28  \n",
              "13                 87               24  \n",
              "14                129               17  \n",
              "15                133               38  \n",
              "16                123                4  \n",
              "17                 93                6  \n",
              "18                119               10  \n",
              "19                132               32  \n",
              "20                120               29  \n",
              "21                168               50  \n",
              "22                215                3  \n",
              "23                160               19  \n",
              "24                202               34  \n",
              "25                107               26  \n",
              "26                112                9  \n",
              "27                178               49  \n",
              "28                180               48  \n",
              "29                 84               43  \n",
              "30                182               36  \n",
              "31                169                7  \n",
              "32                142               22  \n",
              "33                175                5  \n",
              "34                108               46  \n",
              "35                165               47  \n",
              "36                141                1  \n",
              "37                123               30  \n",
              "38                207               44  \n",
              "39                208               23  \n",
              "40                 82               12  \n",
              "41                141               27  \n",
              "42                138               11  \n",
              "43                141                2  \n",
              "44                118               13  \n",
              "45                192                8  \n",
              "46                 81               40  \n",
              "47                208               21  \n",
              "48                147               31  \n",
              "49                117               18  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-173104f0-c88f-4606-883e-2e8794bee806\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>19</td>\n",
              "      <td>186</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>11</td>\n",
              "      <td>201</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>15</td>\n",
              "      <td>167</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>132</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>10</td>\n",
              "      <td>209</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>5</td>\n",
              "      <td>137</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>21</td>\n",
              "      <td>138</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>20</td>\n",
              "      <td>94</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>23</td>\n",
              "      <td>187</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>7</td>\n",
              "      <td>130</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>11</td>\n",
              "      <td>97</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>18</td>\n",
              "      <td>88</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>24</td>\n",
              "      <td>171</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>16</td>\n",
              "      <td>87</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>21</td>\n",
              "      <td>129</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>10</td>\n",
              "      <td>133</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>22</td>\n",
              "      <td>123</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>93</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>18</td>\n",
              "      <td>119</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>19</td>\n",
              "      <td>132</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>17</td>\n",
              "      <td>120</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>5</td>\n",
              "      <td>168</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>5</td>\n",
              "      <td>215</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>23</td>\n",
              "      <td>160</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>5</td>\n",
              "      <td>202</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>4</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>13</td>\n",
              "      <td>107</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>16</td>\n",
              "      <td>112</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>9</td>\n",
              "      <td>178</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>8</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>7</td>\n",
              "      <td>180</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>8</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>5</td>\n",
              "      <td>84</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>18</td>\n",
              "      <td>182</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>19</td>\n",
              "      <td>169</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>6</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>23</td>\n",
              "      <td>142</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>9</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>24</td>\n",
              "      <td>175</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>8</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>11</td>\n",
              "      <td>108</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>11</td>\n",
              "      <td>165</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>17</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>7</td>\n",
              "      <td>None</td>\n",
              "      <td>16</td>\n",
              "      <td>123</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>15</td>\n",
              "      <td>207</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>9</td>\n",
              "      <td>None</td>\n",
              "      <td>11</td>\n",
              "      <td>208</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>24</td>\n",
              "      <td>82</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>13</td>\n",
              "      <td>141</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>14</td>\n",
              "      <td>138</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>21</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4</td>\n",
              "      <td>None</td>\n",
              "      <td>16</td>\n",
              "      <td>118</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>5</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>9</td>\n",
              "      <td>192</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>3</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>21</td>\n",
              "      <td>81</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>6</td>\n",
              "      <td>None</td>\n",
              "      <td>9</td>\n",
              "      <td>208</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>8</td>\n",
              "      <td>None</td>\n",
              "      <td>16</td>\n",
              "      <td>147</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "      <td>21</td>\n",
              "      <td>117</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-173104f0-c88f-4606-883e-2e8794bee806')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-173104f0-c88f-4606-883e-2e8794bee806 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-173104f0-c88f-4606-883e-2e8794bee806');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-817aae61-5a5d-45f5-9fdb-5a29ef3aa079\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-817aae61-5a5d-45f5-9fdb-5a29ef3aa079')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-817aae61-5a5d-45f5-9fdb-5a29ef3aa079 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now I'm going to test the selected model from hyperparameter tuning on the testing dataset to see if the result is satisfactory. Remember that your selected model has been fine-tuned on the validation dataset(in this case, through cross-validation process), and the testing data is just to make sure that your model performs relatively well when encountering unseen data. You might see that the result on test set is relatively worse than what it was on the validation process, but you MUST resist the temptation to modify the hyperparameters once more to yield seemingly superb result on the test set, otherwise you would be disappointed that the model wouldn't perform that well when being launched into production.**"
      ],
      "metadata": {
        "id": "p2Hnt0uvpOms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataframe = reading_housing_data(directory = os.path.join(HOUSING_DATASET_DIRECTORY, \"test.csv\"))\n",
        "test_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "W9gJEE7wvGy8",
        "outputId": "bd651915-6daf-475e-caf5-4d126dad634f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
              "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
              "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
              "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
              "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
              "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
              "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
              "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
              "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
              "...          ...       ...  ...         ...      ...    ...    ...   \n",
              "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
              "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "\n",
              "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0            NaN       0      6    2010        WD         Normal  \n",
              "1           Gar2   12500      6    2010        WD         Normal  \n",
              "2            NaN       0      3    2010        WD         Normal  \n",
              "3            NaN       0      6    2010        WD         Normal  \n",
              "4            NaN       0      1    2010        WD         Normal  \n",
              "...          ...     ...    ...     ...       ...            ...  \n",
              "1454         NaN       0      6    2006        WD         Normal  \n",
              "1455         NaN       0      4    2006        WD        Abnorml  \n",
              "1456         NaN       0      9    2006        WD        Abnorml  \n",
              "1457        Shed     700      7    2006        WD         Normal  \n",
              "1458         NaN       0     11    2006        WD         Normal  \n",
              "\n",
              "[1459 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57eb1c8a-789a-40ef-98b5-8cdfc773faa5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>2915</td>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1936</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>2916</td>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2917</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>160.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2918</td>\n",
              "      <td>85</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10441</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>700</td>\n",
              "      <td>7</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2919</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>9627</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57eb1c8a-789a-40ef-98b5-8cdfc773faa5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57eb1c8a-789a-40ef-98b5-8cdfc773faa5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57eb1c8a-789a-40ef-98b5-8cdfc773faa5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e45f69ff-3325-46e9-8d42-7f1a8fc6a25b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e45f69ff-3325-46e9-8d42-7f1a8fc6a25b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e45f69ff-3325-46e9-8d42-7f1a8fc6a25b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here I create the pipeline used for prediction of new values. I reuse the already-fitted preprocessing pipeline, in combination with the best ML model I have found so far to process the testing dataframe. You can do that by using Pipeline() class provide by scikit-learn and then call the method predict().**"
      ],
      "metadata": {
        "id": "WCiEZRweQh9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "test_full_pipeline = Pipeline([\n",
        "    (\"full_preprocessing_pipeline\", full_pipeline),\n",
        "    (\"best_estimator\", grad_boost_rs.best_estimator_)\n",
        "])\n",
        "test_prediction = test_full_pipeline.predict(test_dataframe)"
      ],
      "metadata": {
        "id": "mXYFShkwvoQ5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYubXA3iw1hT",
        "outputId": "6630dd36-e575-49b7-9af0-468239a5a8a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([125729.46169487, 163546.91877791, 184271.47823923, ...,\n",
              "       164459.28909487, 120412.58599198, 228930.05997328])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I copy the predicted housing values to a csv file and then saved it.**"
      ],
      "metadata": {
        "id": "0lXq9t7hRV0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def saved_prediction_results_to_csv(test_data, test_prediction,\n",
        "                                    saved_directory = os.path.join(HOUSING_DATASET_DIRECTORY, \"test_dataset_prediction.csv\")):\n",
        "    test_prediction_dataframe = pd.DataFrame({\"Id\": test_data[\"Id\"],\n",
        "                                          \"SalePrice\": test_prediction})\n",
        "    test_prediction_dataframe.to_csv(saved_directory, index = False)\n"
      ],
      "metadata": {
        "id": "dN8h-VDZUY7z"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_prediction_results_to_csv(test_dataframe, test_prediction)"
      ],
      "metadata": {
        "id": "q5w4XnbpVOEK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep Learning for House Price Prediction**"
      ],
      "metadata": {
        "id": "KqzHwawlVhyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First dropping the \"Id\" column by the function built earlier: Drop_Column()\n",
        "dropped_train_dataframe = Drop_Column().fit_transform(train_dataframe)"
      ],
      "metadata": {
        "id": "U5xlS0TDOxuM"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to divide the full training set vertically into two Numpy 2D-array, the first one representing numerical columns, the second one for categorical columns. The preprocessing steps for data to be fed into Deep Learning model are going to be relatively complex, with each subset going into different preprocessing pipeline as you will see later.**"
      ],
      "metadata": {
        "id": "flywcTSWdD8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_numerical_and_categorical_subset(dataframe):\n",
        "    return dataframe.select_dtypes(include = ['number']).to_numpy(), dataframe.select_dtypes(include = ['object']).fillna('NaN').to_numpy()"
      ],
      "metadata": {
        "id": "WzrXM4-sWqv8"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Return 2 subsets.\n",
        "num_train_data, cat_train_data = return_numerical_and_categorical_subset(dropped_train_dataframe)"
      ],
      "metadata": {
        "id": "Gq8TUFP6YL7C"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to divide both numerical and categorical subsets into training set and validation set. The function receive 2 subsets along with the labels and the fraction of the full dataset used for the training set.**"
      ],
      "metadata": {
        "id": "2rGGfXRldl0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(num_train_data, cat_train_data, train_labels, train_size = 0.75):\n",
        "\n",
        "    #Using np.random.permutation to shuffle the index of the full training set\n",
        "    random_permutation = np.random.permutation(num_train_data.shape[0])\n",
        "\n",
        "    #Assigning shuffled index to numerical subset of full training set, divide into a train set and a valid set\n",
        "    num_train = num_train_data[random_permutation[: int(num_train_data.shape[0] * train_size)] , :]\n",
        "    num_valid = num_train_data[random_permutation[int(num_train_data.shape[0] * train_size) : ], :]\n",
        "\n",
        "    ##Assigning shuffled index to categorical subset of full training set, divide into a train set and a valid set\n",
        "    cat_train = cat_train_data[random_permutation[: int(num_train_data.shape[0] * train_size)] , :]\n",
        "    cat_valid = cat_train_data[random_permutation[int(num_train_data.shape[0] * train_size) : ], :]\n",
        "\n",
        "    ##Assigning shuffled index to training labels of full training set, divide into a train set and a valid set\n",
        "    train_price = train_labels.to_numpy()\n",
        "    train_label = train_price[random_permutation[ : int(num_train_data.shape[0] * train_size)]] #/ 300000.0\n",
        "    valid_label = train_price[random_permutation[int(num_train_data.shape[0] * train_size) : ]] #/ 300000.0\n",
        "\n",
        "    return (num_train, num_valid), (cat_train, cat_valid), (train_label, valid_label)"
      ],
      "metadata": {
        "id": "Rbce-i6rqnin"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying the function.\n",
        "(num_train, num_valid), (cat_train, cat_valid), (price_train, price_valid) = train_val_split(num_train_data, cat_train_data, train_labels)"
      ],
      "metadata": {
        "id": "VvStguVYWsFJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Informations about training set, validation set and the numbers of numerical and categorical columns\n",
        "print(\"The size of the training set is:\", num_train.shape[0], \"and there are {0} columns of numeric values\".format(num_train.shape[1]))\n",
        "print(\"The size of the valid set is:\", num_valid.shape[0], \"and there are {0} columns of categorical values\".format(cat_valid.shape[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85bXjA6Yh1d",
        "outputId": "b9aad9e1-b8d1-4037-9b31-efe694d1ee2e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the training set is: 1095 and there are 36 columns of numeric values\n",
            "The size of the valid set is: 365 and there are 43 columns of categorical values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputing the missing values in the numerical train set by the mean value of the feature columns which contain the missing values, by sklearn's SimpleImputer function.**"
      ],
      "metadata": {
        "id": "IXq_xaSNg3t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "mean_imputer = SimpleImputer(strategy = \"mean\")\n",
        "num_data = mean_imputer.fit_transform(num_train)#Fitting and transforming numerical train data"
      ],
      "metadata": {
        "id": "Gw6YB8HIg7ij"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After filling the missing values, now we are going to normalize the train set to normal distribution with mean 0 and standard deviation 1. We define the normalization layer keras.layers.Normalization() and then adapt the layers to our train data. Now the normalization layer have \"learned\" the normalization parameters and ready to transform new data once being fed to. We will reuse this already fitted normalization layer later.**"
      ],
      "metadata": {
        "id": "UVhNgnoXYBkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm_layer = keras.layers.Normalization(axis = -1)\n",
        "norm_layer.adapt(num_data)"
      ],
      "metadata": {
        "id": "4jsd5yXliX5b"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we continue with categorical columns preprocessing, when things started becoming more complicated. We define a function \"categorical_columns_preprocessing\", which the first argument is categorical train data, the second one is the number of oov categories for each categorical column and the final is whether we use one-hot-encoding or not.**"
      ],
      "metadata": {
        "id": "6GUEeOLMY7_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are 43 categorical columns, and I will create a list called \"lookup_layers\", which will store all individual lookup layers created for each categorical column. Each lookup layer is keras.layers.StringLookup layer, which will \"learn\" the vocabulary for each categorical column. When new data arrives at these learned lookup layers, these layers will convert categories to learned representation based on the learned vocabulary(\"one hot encoding or int). If the lookup layers encountered unseen categories, it will distribute these categorical values into one or more categories specifically reserved for out-of-vocabulary(oov) categories. You can choose to get output in one-hot-encoding mode or int mode. If you get your output in int mode then that output can be fed into embedding layers. The function will return the converted categorical subset, along with fitted lookup layers which will be utilized later when we build the preprocessing architecture.**"
      ],
      "metadata": {
        "id": "UgW_AVCJZrbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_columns_preprocessing(cat_data, num_oov_indices = 2, one_hot_encoded = False):\n",
        "\n",
        "    num_columns = cat_data.shape[1]\n",
        "    lookup_layers = []#list of lookup layers\n",
        "    result = []#Define the result of transformation of categorical subset\n",
        "\n",
        "    for column_index in tf.range(num_columns):#in the loop we will perform calculation on each categorical column.\n",
        "        vocabulary = cat_data[:, column_index][..., tf.newaxis]\n",
        "\n",
        "        if one_hot_encoded == True:#if one_hot_encoded the output will be in one-hot-encoded mode.\n",
        "            lookup_layer = keras.layers.StringLookup(num_oov_indices = num_oov_indices, output_mode = \"one_hot\")#lookup layer.\n",
        "        else:#if not one_hot_encoded then int mode for embedding later.\n",
        "            lookup_layer = keras.layers.StringLookup(num_oov_indices = num_oov_indices)\n",
        "\n",
        "        lookup_layer.adapt(vocabulary)#lookup layer learns the vocabulary.\n",
        "\n",
        "        lookup_layers.append(lookup_layer)#append the lookup layer into the list\n",
        "        result.append(lookup_layer(vocabulary))\n",
        "\n",
        "    result = tf.concat(result, axis = -1)#convert into the result, just to check if the transformaton is successful.\n",
        "\n",
        "    return result, lookup_layers"
      ],
      "metadata": {
        "id": "XpHzy6YbYuA0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform on the cat_train subset and returned the result along with all 43 lookup layers which we will use later.\n",
        "cat_data, lookup_layers = categorical_columns_preprocessing(tf.constant(cat_train), num_oov_indices = 1, one_hot_encoded = False)"
      ],
      "metadata": {
        "id": "dBGCCizYgX4A"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data#ok successful."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqaRU8EBP5dc",
        "outputId": "bc4e7977-e466-4f12-d638-4b71d7107f65"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1095, 43), dtype=int64, numpy=\n",
              "array([[5, 1, 2, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 3],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 1, 2, 2],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 1, ..., 1, 1, 1]])>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_layers[0].vocabulary_size(), lookup_layers[0].get_vocabulary()\n",
        "#We look at the vocabulary of a random categorical column. Vocabulary size of the column is 6 and you can see the list of learned vocab here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNV-B42YjV5g",
        "outputId": "90ea7920-09e5-417e-ff63-c593cb218f7e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, ['[UNK]', 'RL', 'RM', 'FV', 'RH', 'C (all)'])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform the function but this will return categorical data in one hot encoded mode.\n",
        "cat_data, lookup_layers = categorical_columns_preprocessing(tf.constant(cat_train), num_oov_indices = 1, one_hot_encoded = True)"
      ],
      "metadata": {
        "id": "XTvFaTjNeIcw"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_data #ok one hot encoded."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck8TfxMaeTPH",
        "outputId": "5eebd3c5-82a9-40aa-a8bc-aa1b9edb2813"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1095, 306), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will start building 2 distinct preprocessing pipelines for numerical train subset and categorical train subset, respectively. The first argument for the function \"preprocessing_layers_embedding\" will be \"norm_layer\" to feed the pre-trained normalization layer we use previously. The second argument is \"lookup_layers\" where we feed our pre-trained lookup layers we made previously, to encode categories(string values) into numerical values for every categorical columns. The function is going to be used if in the previous function \"categorical_columns_preprocessing\", you set \"one_hot_encoded\" = False.**"
      ],
      "metadata": {
        "id": "xNGJUGDHThPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For categorical columns, this function will make one Embedding layer for each categorical column, for the embedding layer to learn useful representation for each categories in the learned vocabulary of each categorical column. Here the final argument of the function is the dimensional space to represent the column's learned vocabulary, be it a 4-dimensional space, 5-dimensional or 10-dimensional and so on. It is a hyperparameter you can set. Here the default value is 2, therefore for all 43 categorical columns, there will be 43 different 2-dimensional spaces created to represent the vocabulary. As a result, there wlll be 43 trainable Embedding layers, whose representation of categories in 2-dimensional space will be learned and improved as more data are being fed during training.**"
      ],
      "metadata": {
        "id": "RiGxqjOpU3iz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 different processing pipelines, and fairly complicated processing, so we can't use Sequential API to construct model architecture. We will turn to Functional API instead\n",
        "# and work with Keras symbolic tensors.\n",
        "def preprocessing_layers_embedding(norm_layer, lookup_layers, embedding_output_dim = 2):\n",
        "\n",
        "      num_input = keras.layers.Input(shape = [36], name = \"num_input\")#input tensor for numerical subset.\n",
        "      cat_inputs = [keras.layers.Input(shape = [1], name = \"cat_input_{0}\".format(i), dtype = tf.string) for i in range(43)] #list of input tensor for categorical subset.\n",
        "\n",
        "      num_input_1 = norm_layer(num_input) #numerical subset going through normalization layer\n",
        "      #Actually our numerical data right now is incompleted, as there are missing values in some numerical columns, as demonstrated previously during training data analysis phase.\n",
        "      #Function tf.where to fill missing values with value 0.\n",
        "      num_input_2 = tf.where(tf.math.is_nan(num_input_1), tf.zeros_like(num_input_1), num_input_1)\n",
        "\n",
        "      #For categorical data, encoding string values in these columns into numerical values using pre-trained lookup layers.\n",
        "      cat_inputs_2 = []\n",
        "      for index, cat_input in enumerate(cat_inputs):\n",
        "          cat_inputs_2.append(lookup_layers[index](cat_input))\n",
        "\n",
        "      #Next, for each categorical column, embedding the categories into trainable vectors in Euclidean dimensional space. We make a list to store Keras symbolic tensors of\n",
        "      #43 different categorical columns.\n",
        "      cat_inputs_3 = []\n",
        "      for index, cat_input in enumerate(cat_inputs_2):\n",
        "          embed_layer = keras.layers.Embedding(input_dim = lookup_layers[index].vocabulary_size(),\n",
        "                                                      output_dim = embedding_output_dim, input_length = 1, trainable = True)\n",
        "          cat_inputs_3.append(tf.squeeze(embed_layer(cat_input), axis = 1))\n",
        "\n",
        "      cat_inputs_3 = tf.concat(cat_inputs_3, axis = 1) #concatenate 43 Tensors into 1 final categorical Tensor(1 final transformed categorical subset).\n",
        "      concat_input = tf.concat([num_input_2, cat_inputs_3], axis = 1)#Horizonal concatenation of numerical and categorical subsets, ready for neural network architecture.\n",
        "\n",
        "      return num_input, cat_inputs, concat_input #returning Keras Tensors for the next part: model building."
      ],
      "metadata": {
        "id": "TEzlZcCLMJV6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The next function \"preprocessing_layers_one_hot_encoded\" incorporated virtually the same implementation ideas as the previous one, but there is one difference. This function is used in case you set \"one_hot_encoded\" = True in the function \"categorical_columns_preprocessing\", for it only working with one-hot-encoded categorical data and not embedded data. Therefore the detail implementation of this function will be a little bit simpler than the previous one. In the end it still does the same thing: returning 3 Keras symbolic Tensors, one for numerical input, the next for categorical input and the final one is concatenation Tensor, used as input for building neural network architecture.**"
      ],
      "metadata": {
        "id": "OZSjkKT7nFAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_layers_one_hot_encoded(norm_layer, lookup_layers):\n",
        "    num_input = keras.layers.Input(shape = [36], name = \"num_input\")\n",
        "    cat_inputs = [keras.layers.Input(shape = [1], name = \"cat_input_{0}\".format(i), dtype = tf.string) for i in range(43)]\n",
        "\n",
        "    num_input_1 = norm_layer(num_input)\n",
        "    num_input_2 = tf.where(tf.math.is_nan(num_input_1), tf.zeros_like(num_input_1), num_input_1)\n",
        "\n",
        "    cat_inputs_2 = []\n",
        "    for index, cat_input in enumerate(cat_inputs):\n",
        "        cat_inputs_2.append(lookup_layers[index](cat_input))\n",
        "\n",
        "    cat_inputs_2 = tf.concat(cat_inputs_2, axis = 1)\n",
        "    concat_input = tf.concat([num_input_2, cat_inputs_2], axis = 1)\n",
        "\n",
        "    return num_input, cat_inputs, concat_input"
      ],
      "metadata": {
        "id": "oBVZxFIUdvoQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook we will skip categorical embedding and one-hot-encoded categorical subset instead, as the number of categories for each column is relatively small. So we will use the function \"preprocessing_layers_one_hot_encoded\" instead. Note that the readers of this notebook might want to implement categorical embedding instead, if so please modify the below code cell to use the embedding function before going to the next part.**"
      ],
      "metadata": {
        "id": "9dGbfoxlo7zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_input, cat_inputs, concat_input = preprocessing_layers_one_hot_encoded(norm_layer, lookup_layers)\n",
        "#Returning 3 tensors, with 2 inputs, pre-trained normalization layer and lookup layers."
      ],
      "metadata": {
        "id": "vQJCdKcjdycI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model architecture construction right here! Note that as the preprocessing steps are relatively sophisticated and we might want to make our code more straightforward, easier to understand and debug in case of errors; we have divided the preprocessing steps and the model construction steps into 2 different parts to reduce the potential confusion arising out of entangling everything in just one function. Now as we have come to this part, we can experiment with whatever model architecture coming into our mind, using the concatenated train set as the input. In here we construct the model using Dropout layers and conventional Dense layers as part of the architectture. The function \"build_model\" has 3 inputs for us to feed the 3 outputs of the previous preprocessing function into it.**"
      ],
      "metadata": {
        "id": "iqOZzqHQptVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that our final Keras model in the function(built using the function keras.models.Model()) incorporate both the preprocessing steps and the model construction steps. The reason behind this implementation is to increase the portability of the model, so that we can export the trained model into different environment for inference time without having to worry about how to preprocess raw data ready to be fed into the model. You would just have to bring the raw data in and the Keras Model would take care of the rest(preprocessing, output the prediction).**"
      ],
      "metadata": {
        "id": "XherX35js6W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_input, cat_inputs, concat_input):\n",
        "\n",
        "    dense_1 = keras.layers.Dropout(0.3)(concat_input)#dropout layer\n",
        "\n",
        "    dense_1 = keras.layers.Dense(32, activation = \"elu\", kernel_initializer = \"he_normal\", input_shape = [concat_input.shape[1]])(dense_1)#dense layer\n",
        "    dense_1 = keras.layers.Dropout(0.2)(dense_1)#next Dropout\n",
        "\n",
        "    output = keras.layers.Dense(1)(dense_1)#Output layer, Dense layer with 1 neuron as we want the neural network to output 1 value: house price.\n",
        "\n",
        "    return keras.models.Model(inputs = [num_input] + cat_inputs, outputs = [output]) #Constructing the complete Keras model using the Functional API, with numerical tensor and\n",
        "    #categorical tensor as inputs and the output tensor as the output."
      ],
      "metadata": {
        "id": "Vs9YPLY_kqlv"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_input, cat_inputs, concat_input)\n",
        "#calling the build_model function."
      ],
      "metadata": {
        "id": "Jd4k--zvniwr"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_train_1 = np.hsplit(cat_train, 43)\n",
        "cat_valid_1 = np.hsplit(cat_valid, 43)\n",
        "#Slight transforming ot cat_train Numpy array. Horizontal split by np.hpslit() results in list of categorical columns ready to be feed into the model.\n",
        "#Note: Actually this should be done in our preprocessing function using tf.unstack(), but now I'm so exhuasted, so that's it."
      ],
      "metadata": {
        "id": "elufXgPApatT"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model. Finally we come to this step. First we decide on the loss function to be used (MSE), optimizer to use(Nadam with learning_rate = 0.1, which can be changed if needed), metrics to evaluate the result (RMSE). We also use Early Stopping to stop the training once the model can't improve to be better anymore. Finally fitting the model, specifying training data, validation data, early stopping callback and number of epochs.**"
      ],
      "metadata": {
        "id": "zUqFP3wcwncX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = \"val_root_mean_squared_error\", patience = 50, restore_best_weights = True)#callback\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Nadam(learning_rate = 0.1), loss = \"mse\", metrics = [keras.metrics.RootMeanSquaredError()])\n",
        "model.fit(x = [num_train] + cat_train_1, y = price_train, validation_data = ([num_valid] + cat_valid_1, price_valid),\n",
        "          epochs = 400, callbacks = [early_stop])#fitting data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuWte7GTpOo-",
        "outputId": "d2751feb-1695-4a5d-c985-10f6b543a310"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "35/35 [==============================] - 9s 65ms/step - loss: 38929653760.0000 - root_mean_squared_error: 197305.9844 - val_loss: 32129896448.0000 - val_root_mean_squared_error: 179248.1406\n",
            "Epoch 2/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 30272436224.0000 - root_mean_squared_error: 173989.7500 - val_loss: 19504474112.0000 - val_root_mean_squared_error: 139658.4219\n",
            "Epoch 3/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 15472631808.0000 - root_mean_squared_error: 124389.0312 - val_loss: 6519713280.0000 - val_root_mean_squared_error: 80744.7422\n",
            "Epoch 4/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 5871723008.0000 - root_mean_squared_error: 76627.1641 - val_loss: 2023616128.0000 - val_root_mean_squared_error: 44984.6211\n",
            "Epoch 5/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 3527874048.0000 - root_mean_squared_error: 59395.9102 - val_loss: 1541936256.0000 - val_root_mean_squared_error: 39267.4961\n",
            "Epoch 6/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2843711488.0000 - root_mean_squared_error: 53326.4609 - val_loss: 1404429184.0000 - val_root_mean_squared_error: 37475.7148\n",
            "Epoch 7/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2725120512.0000 - root_mean_squared_error: 52202.6875 - val_loss: 1352063360.0000 - val_root_mean_squared_error: 36770.4141\n",
            "Epoch 8/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2956968960.0000 - root_mean_squared_error: 54378.0195 - val_loss: 1341008768.0000 - val_root_mean_squared_error: 36619.7891\n",
            "Epoch 9/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2612066560.0000 - root_mean_squared_error: 51108.3789 - val_loss: 1338111872.0000 - val_root_mean_squared_error: 36580.2109\n",
            "Epoch 10/400\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 2694340864.0000 - root_mean_squared_error: 51907.0391 - val_loss: 1353853824.0000 - val_root_mean_squared_error: 36794.7539\n",
            "Epoch 11/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 2459255808.0000 - root_mean_squared_error: 49590.8828 - val_loss: 1364832384.0000 - val_root_mean_squared_error: 36943.6367\n",
            "Epoch 12/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 2322766336.0000 - root_mean_squared_error: 48195.0859 - val_loss: 1372715392.0000 - val_root_mean_squared_error: 37050.1719\n",
            "Epoch 13/400\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 2361438976.0000 - root_mean_squared_error: 48594.6367 - val_loss: 1384373376.0000 - val_root_mean_squared_error: 37207.1680\n",
            "Epoch 14/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2425550080.0000 - root_mean_squared_error: 49249.8711 - val_loss: 1365618048.0000 - val_root_mean_squared_error: 36954.2695\n",
            "Epoch 15/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2307128064.0000 - root_mean_squared_error: 48032.5742 - val_loss: 1368518400.0000 - val_root_mean_squared_error: 36993.4922\n",
            "Epoch 16/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2506812672.0000 - root_mean_squared_error: 50068.0820 - val_loss: 1388821376.0000 - val_root_mean_squared_error: 37266.8945\n",
            "Epoch 17/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2410551808.0000 - root_mean_squared_error: 49097.3711 - val_loss: 1366018688.0000 - val_root_mean_squared_error: 36959.6875\n",
            "Epoch 18/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2002138880.0000 - root_mean_squared_error: 44745.2656 - val_loss: 1360049792.0000 - val_root_mean_squared_error: 36878.8516\n",
            "Epoch 19/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2081909120.0000 - root_mean_squared_error: 45627.9414 - val_loss: 1371634688.0000 - val_root_mean_squared_error: 37035.5859\n",
            "Epoch 20/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1968161408.0000 - root_mean_squared_error: 44363.9648 - val_loss: 1357767424.0000 - val_root_mean_squared_error: 36847.8945\n",
            "Epoch 21/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2127723520.0000 - root_mean_squared_error: 46127.2539 - val_loss: 1357816576.0000 - val_root_mean_squared_error: 36848.5625\n",
            "Epoch 22/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2314081280.0000 - root_mean_squared_error: 48104.8984 - val_loss: 1353802752.0000 - val_root_mean_squared_error: 36794.0586\n",
            "Epoch 23/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2121462144.0000 - root_mean_squared_error: 46059.3320 - val_loss: 1349724544.0000 - val_root_mean_squared_error: 36738.5977\n",
            "Epoch 24/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1990368896.0000 - root_mean_squared_error: 44613.5508 - val_loss: 1340776576.0000 - val_root_mean_squared_error: 36616.6172\n",
            "Epoch 25/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2059429376.0000 - root_mean_squared_error: 45380.9375 - val_loss: 1326235008.0000 - val_root_mean_squared_error: 36417.5078\n",
            "Epoch 26/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1940561664.0000 - root_mean_squared_error: 44051.8047 - val_loss: 1348912640.0000 - val_root_mean_squared_error: 36727.5469\n",
            "Epoch 27/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2322889472.0000 - root_mean_squared_error: 48196.3633 - val_loss: 1350806528.0000 - val_root_mean_squared_error: 36753.3203\n",
            "Epoch 28/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 2114296192.0000 - root_mean_squared_error: 45981.4766 - val_loss: 1335218560.0000 - val_root_mean_squared_error: 36540.6406\n",
            "Epoch 29/400\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 1870546688.0000 - root_mean_squared_error: 43249.8164 - val_loss: 1306724608.0000 - val_root_mean_squared_error: 36148.6445\n",
            "Epoch 30/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 2147235840.0000 - root_mean_squared_error: 46338.2773 - val_loss: 1302256384.0000 - val_root_mean_squared_error: 36086.7891\n",
            "Epoch 31/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2020228864.0000 - root_mean_squared_error: 44946.9570 - val_loss: 1328629248.0000 - val_root_mean_squared_error: 36450.3672\n",
            "Epoch 32/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1939709952.0000 - root_mean_squared_error: 44042.1367 - val_loss: 1340707328.0000 - val_root_mean_squared_error: 36615.6719\n",
            "Epoch 33/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2070749696.0000 - root_mean_squared_error: 45505.4883 - val_loss: 1315365120.0000 - val_root_mean_squared_error: 36267.9609\n",
            "Epoch 34/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2114484864.0000 - root_mean_squared_error: 45983.5273 - val_loss: 1287028736.0000 - val_root_mean_squared_error: 35875.1836\n",
            "Epoch 35/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2117891328.0000 - root_mean_squared_error: 46020.5508 - val_loss: 1284471168.0000 - val_root_mean_squared_error: 35839.5195\n",
            "Epoch 36/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2091788160.0000 - root_mean_squared_error: 45736.0703 - val_loss: 1308888960.0000 - val_root_mean_squared_error: 36178.5703\n",
            "Epoch 37/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1742994688.0000 - root_mean_squared_error: 41749.1875 - val_loss: 1319109376.0000 - val_root_mean_squared_error: 36319.5430\n",
            "Epoch 38/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1896903552.0000 - root_mean_squared_error: 43553.4570 - val_loss: 1297350528.0000 - val_root_mean_squared_error: 36018.7500\n",
            "Epoch 39/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2117348096.0000 - root_mean_squared_error: 46014.6484 - val_loss: 1269190400.0000 - val_root_mean_squared_error: 35625.6992\n",
            "Epoch 40/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2077549184.0000 - root_mean_squared_error: 45580.1406 - val_loss: 1261611776.0000 - val_root_mean_squared_error: 35519.1719\n",
            "Epoch 41/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2085586304.0000 - root_mean_squared_error: 45668.2188 - val_loss: 1248413312.0000 - val_root_mean_squared_error: 35332.8906\n",
            "Epoch 42/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1902846464.0000 - root_mean_squared_error: 43621.6289 - val_loss: 1255368704.0000 - val_root_mean_squared_error: 35431.1836\n",
            "Epoch 43/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2088686976.0000 - root_mean_squared_error: 45702.1523 - val_loss: 1253534848.0000 - val_root_mean_squared_error: 35405.2930\n",
            "Epoch 44/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1875040256.0000 - root_mean_squared_error: 43301.7344 - val_loss: 1264908416.0000 - val_root_mean_squared_error: 35565.5508\n",
            "Epoch 45/400\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 1861083776.0000 - root_mean_squared_error: 43140.2812 - val_loss: 1250483200.0000 - val_root_mean_squared_error: 35362.1719\n",
            "Epoch 46/400\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 1952939392.0000 - root_mean_squared_error: 44192.0742 - val_loss: 1239546752.0000 - val_root_mean_squared_error: 35207.1953\n",
            "Epoch 47/400\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 1881259648.0000 - root_mean_squared_error: 43373.4883 - val_loss: 1227384576.0000 - val_root_mean_squared_error: 35034.0469\n",
            "Epoch 48/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2023611904.0000 - root_mean_squared_error: 44984.5742 - val_loss: 1214705152.0000 - val_root_mean_squared_error: 34852.6211\n",
            "Epoch 49/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1823966336.0000 - root_mean_squared_error: 42707.9180 - val_loss: 1202995456.0000 - val_root_mean_squared_error: 34684.2266\n",
            "Epoch 50/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2030989696.0000 - root_mean_squared_error: 45066.5039 - val_loss: 1187889024.0000 - val_root_mean_squared_error: 34465.7656\n",
            "Epoch 51/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 2118673920.0000 - root_mean_squared_error: 46029.0547 - val_loss: 1215270016.0000 - val_root_mean_squared_error: 34860.7227\n",
            "Epoch 52/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1936574976.0000 - root_mean_squared_error: 44006.5312 - val_loss: 1217926400.0000 - val_root_mean_squared_error: 34898.8008\n",
            "Epoch 53/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1872821376.0000 - root_mean_squared_error: 43276.1055 - val_loss: 1254396416.0000 - val_root_mean_squared_error: 35417.4609\n",
            "Epoch 54/400\n",
            "35/35 [==============================] - 1s 17ms/step - loss: 2001088256.0000 - root_mean_squared_error: 44733.5234 - val_loss: 1289428352.0000 - val_root_mean_squared_error: 35908.6094\n",
            "Epoch 55/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1674501760.0000 - root_mean_squared_error: 40920.6758 - val_loss: 1228255872.0000 - val_root_mean_squared_error: 35046.4805\n",
            "Epoch 56/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2080333824.0000 - root_mean_squared_error: 45610.6758 - val_loss: 1236142464.0000 - val_root_mean_squared_error: 35158.8164\n",
            "Epoch 57/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2006089984.0000 - root_mean_squared_error: 44789.3945 - val_loss: 1208363392.0000 - val_root_mean_squared_error: 34761.5195\n",
            "Epoch 58/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1724177408.0000 - root_mean_squared_error: 41523.2148 - val_loss: 1240300928.0000 - val_root_mean_squared_error: 35217.9062\n",
            "Epoch 59/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1915275392.0000 - root_mean_squared_error: 43763.8594 - val_loss: 1231908608.0000 - val_root_mean_squared_error: 35098.5547\n",
            "Epoch 60/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1748637952.0000 - root_mean_squared_error: 41816.7188 - val_loss: 1232367104.0000 - val_root_mean_squared_error: 35105.0859\n",
            "Epoch 61/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1999375872.0000 - root_mean_squared_error: 44714.3789 - val_loss: 1241347968.0000 - val_root_mean_squared_error: 35232.7656\n",
            "Epoch 62/400\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 1838514304.0000 - root_mean_squared_error: 42877.8984 - val_loss: 1198501888.0000 - val_root_mean_squared_error: 34619.3867\n",
            "Epoch 63/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1885224320.0000 - root_mean_squared_error: 43419.1680 - val_loss: 1167566848.0000 - val_root_mean_squared_error: 34169.6758\n",
            "Epoch 64/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 2067408640.0000 - root_mean_squared_error: 45468.7656 - val_loss: 1167886720.0000 - val_root_mean_squared_error: 34174.3555\n",
            "Epoch 65/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1835206784.0000 - root_mean_squared_error: 42839.3125 - val_loss: 1162380928.0000 - val_root_mean_squared_error: 34093.7070\n",
            "Epoch 66/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 2157339392.0000 - root_mean_squared_error: 46447.1680 - val_loss: 1204165248.0000 - val_root_mean_squared_error: 34701.0859\n",
            "Epoch 67/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1897967744.0000 - root_mean_squared_error: 43565.6719 - val_loss: 1180678400.0000 - val_root_mean_squared_error: 34361.0000\n",
            "Epoch 68/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1875044224.0000 - root_mean_squared_error: 43301.7812 - val_loss: 1082946432.0000 - val_root_mean_squared_error: 32908.1523\n",
            "Epoch 69/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1846724864.0000 - root_mean_squared_error: 42973.5352 - val_loss: 1099975296.0000 - val_root_mean_squared_error: 33165.8750\n",
            "Epoch 70/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1787304704.0000 - root_mean_squared_error: 42276.5273 - val_loss: 1072836096.0000 - val_root_mean_squared_error: 32754.1758\n",
            "Epoch 71/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1860715136.0000 - root_mean_squared_error: 43136.0078 - val_loss: 1094365312.0000 - val_root_mean_squared_error: 33081.1914\n",
            "Epoch 72/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2034009088.0000 - root_mean_squared_error: 45099.9883 - val_loss: 1038462016.0000 - val_root_mean_squared_error: 32225.1758\n",
            "Epoch 73/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1808912256.0000 - root_mean_squared_error: 42531.3086 - val_loss: 1048573056.0000 - val_root_mean_squared_error: 32381.6777\n",
            "Epoch 74/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1862437504.0000 - root_mean_squared_error: 43155.9648 - val_loss: 1054546688.0000 - val_root_mean_squared_error: 32473.7852\n",
            "Epoch 75/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1920627840.0000 - root_mean_squared_error: 43824.9688 - val_loss: 1052643712.0000 - val_root_mean_squared_error: 32444.4707\n",
            "Epoch 76/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1736636800.0000 - root_mean_squared_error: 41672.9727 - val_loss: 1060187712.0000 - val_root_mean_squared_error: 32560.5234\n",
            "Epoch 77/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1889041408.0000 - root_mean_squared_error: 43463.1055 - val_loss: 1049495680.0000 - val_root_mean_squared_error: 32395.9199\n",
            "Epoch 78/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1939483520.0000 - root_mean_squared_error: 44039.5664 - val_loss: 1067724800.0000 - val_root_mean_squared_error: 32676.0586\n",
            "Epoch 79/400\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 2058290048.0000 - root_mean_squared_error: 45368.3828 - val_loss: 1042357952.0000 - val_root_mean_squared_error: 32285.5684\n",
            "Epoch 80/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1623221632.0000 - root_mean_squared_error: 40289.2227 - val_loss: 1035632384.0000 - val_root_mean_squared_error: 32181.2422\n",
            "Epoch 81/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1690898560.0000 - root_mean_squared_error: 41120.5352 - val_loss: 1035445248.0000 - val_root_mean_squared_error: 32178.3340\n",
            "Epoch 82/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 2019202304.0000 - root_mean_squared_error: 44935.5352 - val_loss: 1043581824.0000 - val_root_mean_squared_error: 32304.5176\n",
            "Epoch 83/400\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 1808844416.0000 - root_mean_squared_error: 42530.5117 - val_loss: 1033763584.0000 - val_root_mean_squared_error: 32152.1934\n",
            "Epoch 84/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1840523008.0000 - root_mean_squared_error: 42901.3164 - val_loss: 1059425536.0000 - val_root_mean_squared_error: 32548.8164\n",
            "Epoch 85/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1692344192.0000 - root_mean_squared_error: 41138.1094 - val_loss: 1075887488.0000 - val_root_mean_squared_error: 32800.7227\n",
            "Epoch 86/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1798379008.0000 - root_mean_squared_error: 42407.2969 - val_loss: 1089908736.0000 - val_root_mean_squared_error: 33013.7656\n",
            "Epoch 87/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1595843200.0000 - root_mean_squared_error: 39948.0039 - val_loss: 1070894592.0000 - val_root_mean_squared_error: 32724.5254\n",
            "Epoch 88/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1986803712.0000 - root_mean_squared_error: 44573.5742 - val_loss: 1024530688.0000 - val_root_mean_squared_error: 32008.2910\n",
            "Epoch 89/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1710712704.0000 - root_mean_squared_error: 41360.7656 - val_loss: 1038104512.0000 - val_root_mean_squared_error: 32219.6289\n",
            "Epoch 90/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1877481472.0000 - root_mean_squared_error: 43329.9141 - val_loss: 1054981760.0000 - val_root_mean_squared_error: 32480.4824\n",
            "Epoch 91/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1935195008.0000 - root_mean_squared_error: 43990.8516 - val_loss: 1024884224.0000 - val_root_mean_squared_error: 32013.8125\n",
            "Epoch 92/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1813942912.0000 - root_mean_squared_error: 42590.4062 - val_loss: 1074808704.0000 - val_root_mean_squared_error: 32784.2734\n",
            "Epoch 93/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1880787712.0000 - root_mean_squared_error: 43368.0469 - val_loss: 1108212736.0000 - val_root_mean_squared_error: 33289.8281\n",
            "Epoch 94/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1923153408.0000 - root_mean_squared_error: 43853.7734 - val_loss: 1071656064.0000 - val_root_mean_squared_error: 32736.1582\n",
            "Epoch 95/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1860325632.0000 - root_mean_squared_error: 43131.4922 - val_loss: 1075781248.0000 - val_root_mean_squared_error: 32799.1016\n",
            "Epoch 96/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 1694684032.0000 - root_mean_squared_error: 41166.5391 - val_loss: 1055371648.0000 - val_root_mean_squared_error: 32486.4844\n",
            "Epoch 97/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 1994340352.0000 - root_mean_squared_error: 44658.0391 - val_loss: 1115535616.0000 - val_root_mean_squared_error: 33399.6328\n",
            "Epoch 98/400\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 1760120960.0000 - root_mean_squared_error: 41953.7969 - val_loss: 1116838144.0000 - val_root_mean_squared_error: 33419.1289\n",
            "Epoch 99/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1918562816.0000 - root_mean_squared_error: 43801.4023 - val_loss: 1106689152.0000 - val_root_mean_squared_error: 33266.9375\n",
            "Epoch 100/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1746283776.0000 - root_mean_squared_error: 41788.5586 - val_loss: 1140856064.0000 - val_root_mean_squared_error: 33776.5586\n",
            "Epoch 101/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1676980992.0000 - root_mean_squared_error: 40950.9570 - val_loss: 1155222784.0000 - val_root_mean_squared_error: 33988.5703\n",
            "Epoch 102/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1872997632.0000 - root_mean_squared_error: 43278.1445 - val_loss: 1155244800.0000 - val_root_mean_squared_error: 33988.8906\n",
            "Epoch 103/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 1778339712.0000 - root_mean_squared_error: 42170.3633 - val_loss: 1105225728.0000 - val_root_mean_squared_error: 33244.9375\n",
            "Epoch 104/400\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 1969251584.0000 - root_mean_squared_error: 44376.2500 - val_loss: 1089972352.0000 - val_root_mean_squared_error: 33014.7305\n",
            "Epoch 105/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 1895380864.0000 - root_mean_squared_error: 43535.9727 - val_loss: 1057665472.0000 - val_root_mean_squared_error: 32521.7695\n",
            "Epoch 106/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1803777920.0000 - root_mean_squared_error: 42470.9062 - val_loss: 1066779648.0000 - val_root_mean_squared_error: 32661.5918\n",
            "Epoch 107/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1899423104.0000 - root_mean_squared_error: 43582.3711 - val_loss: 1094908032.0000 - val_root_mean_squared_error: 33089.3945\n",
            "Epoch 108/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1892901376.0000 - root_mean_squared_error: 43507.4844 - val_loss: 1071852928.0000 - val_root_mean_squared_error: 32739.1641\n",
            "Epoch 109/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1565936384.0000 - root_mean_squared_error: 39571.9141 - val_loss: 1011884096.0000 - val_root_mean_squared_error: 31810.1250\n",
            "Epoch 110/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1740131200.0000 - root_mean_squared_error: 41714.8789 - val_loss: 1027460288.0000 - val_root_mean_squared_error: 32054.0215\n",
            "Epoch 111/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1843833472.0000 - root_mean_squared_error: 42939.8828 - val_loss: 1066783232.0000 - val_root_mean_squared_error: 32661.6465\n",
            "Epoch 112/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1780844032.0000 - root_mean_squared_error: 42200.0469 - val_loss: 1040930880.0000 - val_root_mean_squared_error: 32263.4609\n",
            "Epoch 113/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1727068928.0000 - root_mean_squared_error: 41558.0195 - val_loss: 1081124480.0000 - val_root_mean_squared_error: 32880.4570\n",
            "Epoch 114/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1692397440.0000 - root_mean_squared_error: 41138.7578 - val_loss: 1060467584.0000 - val_root_mean_squared_error: 32564.8203\n",
            "Epoch 115/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1729217280.0000 - root_mean_squared_error: 41583.8555 - val_loss: 1079636480.0000 - val_root_mean_squared_error: 32857.8203\n",
            "Epoch 116/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1731093504.0000 - root_mean_squared_error: 41606.4102 - val_loss: 1046549056.0000 - val_root_mean_squared_error: 32350.4102\n",
            "Epoch 117/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1777870720.0000 - root_mean_squared_error: 42164.8047 - val_loss: 1070748096.0000 - val_root_mean_squared_error: 32722.2871\n",
            "Epoch 118/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1818699520.0000 - root_mean_squared_error: 42646.2109 - val_loss: 1073139456.0000 - val_root_mean_squared_error: 32758.8066\n",
            "Epoch 119/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1662840064.0000 - root_mean_squared_error: 40777.9336 - val_loss: 1100077056.0000 - val_root_mean_squared_error: 33167.4102\n",
            "Epoch 120/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1666782976.0000 - root_mean_squared_error: 40826.2539 - val_loss: 1093087104.0000 - val_root_mean_squared_error: 33061.8672\n",
            "Epoch 121/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1676441984.0000 - root_mean_squared_error: 40944.3750 - val_loss: 1071910848.0000 - val_root_mean_squared_error: 32740.0488\n",
            "Epoch 122/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1535429632.0000 - root_mean_squared_error: 39184.5586 - val_loss: 1060237888.0000 - val_root_mean_squared_error: 32561.2949\n",
            "Epoch 123/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1750760192.0000 - root_mean_squared_error: 41842.0859 - val_loss: 1007705088.0000 - val_root_mean_squared_error: 31744.3711\n",
            "Epoch 124/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1648537728.0000 - root_mean_squared_error: 40602.1875 - val_loss: 1021094144.0000 - val_root_mean_squared_error: 31954.5625\n",
            "Epoch 125/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1825366400.0000 - root_mean_squared_error: 42724.3047 - val_loss: 985794816.0000 - val_root_mean_squared_error: 31397.3691\n",
            "Epoch 126/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1754846336.0000 - root_mean_squared_error: 41890.8867 - val_loss: 975243904.0000 - val_root_mean_squared_error: 31228.8945\n",
            "Epoch 127/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1724406400.0000 - root_mean_squared_error: 41525.9727 - val_loss: 980025536.0000 - val_root_mean_squared_error: 31305.3594\n",
            "Epoch 128/400\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 1642915840.0000 - root_mean_squared_error: 40532.8984 - val_loss: 949478912.0000 - val_root_mean_squared_error: 30813.6152\n",
            "Epoch 129/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1761962368.0000 - root_mean_squared_error: 41975.7344 - val_loss: 968807104.0000 - val_root_mean_squared_error: 31125.6660\n",
            "Epoch 130/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 1747899776.0000 - root_mean_squared_error: 41807.8906 - val_loss: 976513216.0000 - val_root_mean_squared_error: 31249.2109\n",
            "Epoch 131/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1827573760.0000 - root_mean_squared_error: 42750.1328 - val_loss: 988400512.0000 - val_root_mean_squared_error: 31438.8379\n",
            "Epoch 132/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1993252096.0000 - root_mean_squared_error: 44645.8516 - val_loss: 1050851520.0000 - val_root_mean_squared_error: 32416.8398\n",
            "Epoch 133/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1797378560.0000 - root_mean_squared_error: 42395.5000 - val_loss: 1033927360.0000 - val_root_mean_squared_error: 32154.7402\n",
            "Epoch 134/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1871367296.0000 - root_mean_squared_error: 43259.3047 - val_loss: 1043645888.0000 - val_root_mean_squared_error: 32305.5078\n",
            "Epoch 135/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1893988352.0000 - root_mean_squared_error: 43519.9766 - val_loss: 1032538240.0000 - val_root_mean_squared_error: 32133.1328\n",
            "Epoch 136/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1769808256.0000 - root_mean_squared_error: 42069.0898 - val_loss: 1012158656.0000 - val_root_mean_squared_error: 31814.4414\n",
            "Epoch 137/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1708550528.0000 - root_mean_squared_error: 41334.6172 - val_loss: 1063283648.0000 - val_root_mean_squared_error: 32608.0293\n",
            "Epoch 138/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1792829952.0000 - root_mean_squared_error: 42341.8242 - val_loss: 1053152384.0000 - val_root_mean_squared_error: 32452.3086\n",
            "Epoch 139/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1574032384.0000 - root_mean_squared_error: 39674.0781 - val_loss: 1028267008.0000 - val_root_mean_squared_error: 32066.6016\n",
            "Epoch 140/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1662027136.0000 - root_mean_squared_error: 40767.9648 - val_loss: 975959936.0000 - val_root_mean_squared_error: 31240.3574\n",
            "Epoch 141/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1753826176.0000 - root_mean_squared_error: 41878.7070 - val_loss: 977170816.0000 - val_root_mean_squared_error: 31259.7305\n",
            "Epoch 142/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1865686272.0000 - root_mean_squared_error: 43193.5898 - val_loss: 1028603072.0000 - val_root_mean_squared_error: 32071.8418\n",
            "Epoch 143/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1584385408.0000 - root_mean_squared_error: 39804.3398 - val_loss: 1035891712.0000 - val_root_mean_squared_error: 32185.2715\n",
            "Epoch 144/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1796952448.0000 - root_mean_squared_error: 42390.4766 - val_loss: 1030810816.0000 - val_root_mean_squared_error: 32106.2422\n",
            "Epoch 145/400\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 1511980160.0000 - root_mean_squared_error: 38884.1875 - val_loss: 1065069184.0000 - val_root_mean_squared_error: 32635.3965\n",
            "Epoch 146/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 1770955392.0000 - root_mean_squared_error: 42082.7188 - val_loss: 1043435904.0000 - val_root_mean_squared_error: 32302.2578\n",
            "Epoch 147/400\n",
            "35/35 [==============================] - 1s 29ms/step - loss: 1659957632.0000 - root_mean_squared_error: 40742.5781 - val_loss: 1060129984.0000 - val_root_mean_squared_error: 32559.6367\n",
            "Epoch 148/400\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 1598792576.0000 - root_mean_squared_error: 39984.9023 - val_loss: 1073824640.0000 - val_root_mean_squared_error: 32769.2617\n",
            "Epoch 149/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1962811392.0000 - root_mean_squared_error: 44303.6250 - val_loss: 1117073280.0000 - val_root_mean_squared_error: 33422.6445\n",
            "Epoch 150/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1420123776.0000 - root_mean_squared_error: 37684.5273 - val_loss: 1051471872.0000 - val_root_mean_squared_error: 32426.4062\n",
            "Epoch 151/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1445668736.0000 - root_mean_squared_error: 38021.9492 - val_loss: 1034685952.0000 - val_root_mean_squared_error: 32166.5332\n",
            "Epoch 152/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1457363456.0000 - root_mean_squared_error: 38175.4297 - val_loss: 1000496000.0000 - val_root_mean_squared_error: 31630.6172\n",
            "Epoch 153/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1685512832.0000 - root_mean_squared_error: 41054.9961 - val_loss: 1014467584.0000 - val_root_mean_squared_error: 31850.7070\n",
            "Epoch 154/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1783955712.0000 - root_mean_squared_error: 42236.8984 - val_loss: 973829888.0000 - val_root_mean_squared_error: 31206.2461\n",
            "Epoch 155/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1751437056.0000 - root_mean_squared_error: 41850.1719 - val_loss: 945377088.0000 - val_root_mean_squared_error: 30746.9844\n",
            "Epoch 156/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1622086400.0000 - root_mean_squared_error: 40275.1328 - val_loss: 910307712.0000 - val_root_mean_squared_error: 30171.3066\n",
            "Epoch 157/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1781606272.0000 - root_mean_squared_error: 42209.0781 - val_loss: 938309184.0000 - val_root_mean_squared_error: 30631.8320\n",
            "Epoch 158/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1420076672.0000 - root_mean_squared_error: 37683.9023 - val_loss: 972612160.0000 - val_root_mean_squared_error: 31186.7305\n",
            "Epoch 159/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1789626368.0000 - root_mean_squared_error: 42303.9766 - val_loss: 1035500032.0000 - val_root_mean_squared_error: 32179.1855\n",
            "Epoch 160/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1701279488.0000 - root_mean_squared_error: 41246.5703 - val_loss: 1007559552.0000 - val_root_mean_squared_error: 31742.0781\n",
            "Epoch 161/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1551210880.0000 - root_mean_squared_error: 39385.4141 - val_loss: 980030400.0000 - val_root_mean_squared_error: 31305.4375\n",
            "Epoch 162/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1583676800.0000 - root_mean_squared_error: 39795.4375 - val_loss: 987823232.0000 - val_root_mean_squared_error: 31429.6543\n",
            "Epoch 163/400\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 1637288704.0000 - root_mean_squared_error: 40463.4258 - val_loss: 1051038336.0000 - val_root_mean_squared_error: 32419.7207\n",
            "Epoch 164/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1819596416.0000 - root_mean_squared_error: 42656.7266 - val_loss: 999700352.0000 - val_root_mean_squared_error: 31618.0371\n",
            "Epoch 165/400\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 1681042176.0000 - root_mean_squared_error: 41000.5117 - val_loss: 1002997696.0000 - val_root_mean_squared_error: 31670.1387\n",
            "Epoch 166/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1659852288.0000 - root_mean_squared_error: 40741.2852 - val_loss: 1036356224.0000 - val_root_mean_squared_error: 32192.4863\n",
            "Epoch 167/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1668447744.0000 - root_mean_squared_error: 40846.6367 - val_loss: 1009954048.0000 - val_root_mean_squared_error: 31779.7734\n",
            "Epoch 168/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1529157248.0000 - root_mean_squared_error: 39104.4375 - val_loss: 1003467648.0000 - val_root_mean_squared_error: 31677.5566\n",
            "Epoch 169/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1696676480.0000 - root_mean_squared_error: 41190.7305 - val_loss: 988670720.0000 - val_root_mean_squared_error: 31443.1348\n",
            "Epoch 170/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1756161408.0000 - root_mean_squared_error: 41906.5781 - val_loss: 946309952.0000 - val_root_mean_squared_error: 30762.1504\n",
            "Epoch 171/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1785094528.0000 - root_mean_squared_error: 42250.3789 - val_loss: 957247360.0000 - val_root_mean_squared_error: 30939.4141\n",
            "Epoch 172/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1510030464.0000 - root_mean_squared_error: 38859.1094 - val_loss: 974327936.0000 - val_root_mean_squared_error: 31214.2266\n",
            "Epoch 173/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1663031168.0000 - root_mean_squared_error: 40780.2773 - val_loss: 1046887296.0000 - val_root_mean_squared_error: 32355.6367\n",
            "Epoch 174/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1685187456.0000 - root_mean_squared_error: 41051.0352 - val_loss: 920623936.0000 - val_root_mean_squared_error: 30341.7852\n",
            "Epoch 175/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1861138432.0000 - root_mean_squared_error: 43140.9141 - val_loss: 910971520.0000 - val_root_mean_squared_error: 30182.3047\n",
            "Epoch 176/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1339910016.0000 - root_mean_squared_error: 36604.7812 - val_loss: 920770304.0000 - val_root_mean_squared_error: 30344.1973\n",
            "Epoch 177/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1579860096.0000 - root_mean_squared_error: 39747.4531 - val_loss: 902594816.0000 - val_root_mean_squared_error: 30043.2148\n",
            "Epoch 178/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1699112960.0000 - root_mean_squared_error: 41220.2969 - val_loss: 920015040.0000 - val_root_mean_squared_error: 30331.7500\n",
            "Epoch 179/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1649249024.0000 - root_mean_squared_error: 40610.9453 - val_loss: 1009537472.0000 - val_root_mean_squared_error: 31773.2188\n",
            "Epoch 180/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1480360320.0000 - root_mean_squared_error: 38475.4492 - val_loss: 966072704.0000 - val_root_mean_squared_error: 31081.7090\n",
            "Epoch 181/400\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 1666176000.0000 - root_mean_squared_error: 40818.8203 - val_loss: 933674432.0000 - val_root_mean_squared_error: 30556.0859\n",
            "Epoch 182/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1408359168.0000 - root_mean_squared_error: 37528.1133 - val_loss: 919613120.0000 - val_root_mean_squared_error: 30325.1230\n",
            "Epoch 183/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1448276480.0000 - root_mean_squared_error: 38056.2266 - val_loss: 952246848.0000 - val_root_mean_squared_error: 30858.4961\n",
            "Epoch 184/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1718045952.0000 - root_mean_squared_error: 41449.3164 - val_loss: 1027483264.0000 - val_root_mean_squared_error: 32054.3789\n",
            "Epoch 185/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1558915200.0000 - root_mean_squared_error: 39483.0977 - val_loss: 1085402624.0000 - val_root_mean_squared_error: 32945.4492\n",
            "Epoch 186/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1737038976.0000 - root_mean_squared_error: 41677.8008 - val_loss: 1041991936.0000 - val_root_mean_squared_error: 32279.9004\n",
            "Epoch 187/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1613251584.0000 - root_mean_squared_error: 40165.3008 - val_loss: 1030455488.0000 - val_root_mean_squared_error: 32100.7090\n",
            "Epoch 188/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1822092032.0000 - root_mean_squared_error: 42685.9688 - val_loss: 979556160.0000 - val_root_mean_squared_error: 31297.8613\n",
            "Epoch 189/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1585592576.0000 - root_mean_squared_error: 39819.5000 - val_loss: 978570880.0000 - val_root_mean_squared_error: 31282.1172\n",
            "Epoch 190/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1559617920.0000 - root_mean_squared_error: 39491.9961 - val_loss: 975968384.0000 - val_root_mean_squared_error: 31240.4922\n",
            "Epoch 191/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1471558272.0000 - root_mean_squared_error: 38360.8945 - val_loss: 961266816.0000 - val_root_mean_squared_error: 31004.3027\n",
            "Epoch 192/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1431261056.0000 - root_mean_squared_error: 37832.0117 - val_loss: 974704448.0000 - val_root_mean_squared_error: 31220.2559\n",
            "Epoch 193/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1555181056.0000 - root_mean_squared_error: 39435.7812 - val_loss: 929577600.0000 - val_root_mean_squared_error: 30488.9746\n",
            "Epoch 194/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1475048320.0000 - root_mean_squared_error: 38406.3594 - val_loss: 948528896.0000 - val_root_mean_squared_error: 30798.1953\n",
            "Epoch 195/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1521029248.0000 - root_mean_squared_error: 39000.3750 - val_loss: 938320576.0000 - val_root_mean_squared_error: 30632.0176\n",
            "Epoch 196/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1544547200.0000 - root_mean_squared_error: 39300.7266 - val_loss: 974488448.0000 - val_root_mean_squared_error: 31216.7969\n",
            "Epoch 197/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1546047616.0000 - root_mean_squared_error: 39319.8125 - val_loss: 977389184.0000 - val_root_mean_squared_error: 31263.2246\n",
            "Epoch 198/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1730391552.0000 - root_mean_squared_error: 41597.9727 - val_loss: 923285376.0000 - val_root_mean_squared_error: 30385.6113\n",
            "Epoch 199/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1624186240.0000 - root_mean_squared_error: 40301.1953 - val_loss: 912149056.0000 - val_root_mean_squared_error: 30201.8047\n",
            "Epoch 200/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1456644736.0000 - root_mean_squared_error: 38166.0156 - val_loss: 884774784.0000 - val_root_mean_squared_error: 29745.1641\n",
            "Epoch 201/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1671931776.0000 - root_mean_squared_error: 40889.2617 - val_loss: 902868032.0000 - val_root_mean_squared_error: 30047.7617\n",
            "Epoch 202/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1460244096.0000 - root_mean_squared_error: 38213.1406 - val_loss: 920652352.0000 - val_root_mean_squared_error: 30342.2539\n",
            "Epoch 203/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1572650496.0000 - root_mean_squared_error: 39656.6562 - val_loss: 947437184.0000 - val_root_mean_squared_error: 30780.4668\n",
            "Epoch 204/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1623600128.0000 - root_mean_squared_error: 40293.9219 - val_loss: 906084928.0000 - val_root_mean_squared_error: 30101.2441\n",
            "Epoch 205/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1624895872.0000 - root_mean_squared_error: 40309.9961 - val_loss: 870155520.0000 - val_root_mean_squared_error: 29498.3984\n",
            "Epoch 206/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1588490880.0000 - root_mean_squared_error: 39855.8750 - val_loss: 907482176.0000 - val_root_mean_squared_error: 30124.4453\n",
            "Epoch 207/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1686677632.0000 - root_mean_squared_error: 41069.1797 - val_loss: 903866496.0000 - val_root_mean_squared_error: 30064.3730\n",
            "Epoch 208/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1428054784.0000 - root_mean_squared_error: 37789.6094 - val_loss: 922166272.0000 - val_root_mean_squared_error: 30367.1914\n",
            "Epoch 209/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1728510720.0000 - root_mean_squared_error: 41575.3594 - val_loss: 894357824.0000 - val_root_mean_squared_error: 29905.8164\n",
            "Epoch 210/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1607738496.0000 - root_mean_squared_error: 40096.6133 - val_loss: 844305856.0000 - val_root_mean_squared_error: 29056.9414\n",
            "Epoch 211/400\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 1377641728.0000 - root_mean_squared_error: 37116.5938 - val_loss: 839856256.0000 - val_root_mean_squared_error: 28980.2734\n",
            "Epoch 212/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1744679808.0000 - root_mean_squared_error: 41769.3672 - val_loss: 907710208.0000 - val_root_mean_squared_error: 30128.2285\n",
            "Epoch 213/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1875503744.0000 - root_mean_squared_error: 43307.0859 - val_loss: 884684096.0000 - val_root_mean_squared_error: 29743.6387\n",
            "Epoch 214/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1561793920.0000 - root_mean_squared_error: 39519.5391 - val_loss: 870469504.0000 - val_root_mean_squared_error: 29503.7207\n",
            "Epoch 215/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1594238848.0000 - root_mean_squared_error: 39927.9219 - val_loss: 879028800.0000 - val_root_mean_squared_error: 29648.4199\n",
            "Epoch 216/400\n",
            "35/35 [==============================] - 1s 22ms/step - loss: 1383205632.0000 - root_mean_squared_error: 37191.4727 - val_loss: 882726016.0000 - val_root_mean_squared_error: 29710.7051\n",
            "Epoch 217/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1580156160.0000 - root_mean_squared_error: 39751.1758 - val_loss: 881378112.0000 - val_root_mean_squared_error: 29688.0117\n",
            "Epoch 218/400\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 1424250240.0000 - root_mean_squared_error: 37739.2383 - val_loss: 924991232.0000 - val_root_mean_squared_error: 30413.6680\n",
            "Epoch 219/400\n",
            "35/35 [==============================] - 1s 40ms/step - loss: 1717727360.0000 - root_mean_squared_error: 41445.4727 - val_loss: 895269632.0000 - val_root_mean_squared_error: 29921.0566\n",
            "Epoch 220/400\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 1546573184.0000 - root_mean_squared_error: 39326.4922 - val_loss: 858364736.0000 - val_root_mean_squared_error: 29297.8613\n",
            "Epoch 221/400\n",
            "35/35 [==============================] - 1s 38ms/step - loss: 1416039680.0000 - root_mean_squared_error: 37630.3008 - val_loss: 871683584.0000 - val_root_mean_squared_error: 29524.2871\n",
            "Epoch 222/400\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 1509556864.0000 - root_mean_squared_error: 38853.0156 - val_loss: 878866752.0000 - val_root_mean_squared_error: 29645.6875\n",
            "Epoch 223/400\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 1488367232.0000 - root_mean_squared_error: 38579.3633 - val_loss: 861791424.0000 - val_root_mean_squared_error: 29356.2832\n",
            "Epoch 224/400\n",
            "35/35 [==============================] - 1s 35ms/step - loss: 1485285376.0000 - root_mean_squared_error: 38539.3984 - val_loss: 836145280.0000 - val_root_mean_squared_error: 28916.1758\n",
            "Epoch 225/400\n",
            "35/35 [==============================] - 2s 58ms/step - loss: 1607326080.0000 - root_mean_squared_error: 40091.4727 - val_loss: 812586688.0000 - val_root_mean_squared_error: 28505.9062\n",
            "Epoch 226/400\n",
            "35/35 [==============================] - 2s 55ms/step - loss: 1272806912.0000 - root_mean_squared_error: 35676.4219 - val_loss: 817454400.0000 - val_root_mean_squared_error: 28591.1582\n",
            "Epoch 227/400\n",
            "35/35 [==============================] - 2s 49ms/step - loss: 1531475712.0000 - root_mean_squared_error: 39134.0742 - val_loss: 808935424.0000 - val_root_mean_squared_error: 28441.7891\n",
            "Epoch 228/400\n",
            "35/35 [==============================] - 1s 41ms/step - loss: 1419352704.0000 - root_mean_squared_error: 37674.2969 - val_loss: 866564672.0000 - val_root_mean_squared_error: 29437.4707\n",
            "Epoch 229/400\n",
            "35/35 [==============================] - 1s 42ms/step - loss: 1510411264.0000 - root_mean_squared_error: 38864.0078 - val_loss: 837180480.0000 - val_root_mean_squared_error: 28934.0703\n",
            "Epoch 230/400\n",
            "35/35 [==============================] - 1s 34ms/step - loss: 1506134528.0000 - root_mean_squared_error: 38808.9492 - val_loss: 846438912.0000 - val_root_mean_squared_error: 29093.6230\n",
            "Epoch 231/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1402228864.0000 - root_mean_squared_error: 37446.3477 - val_loss: 850428352.0000 - val_root_mean_squared_error: 29162.1055\n",
            "Epoch 232/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 1543899008.0000 - root_mean_squared_error: 39292.4805 - val_loss: 888691584.0000 - val_root_mean_squared_error: 29810.9316\n",
            "Epoch 233/400\n",
            "35/35 [==============================] - 1s 39ms/step - loss: 1532226176.0000 - root_mean_squared_error: 39143.6602 - val_loss: 908097600.0000 - val_root_mean_squared_error: 30134.6582\n",
            "Epoch 234/400\n",
            "35/35 [==============================] - 1s 39ms/step - loss: 1627768832.0000 - root_mean_squared_error: 40345.6172 - val_loss: 930014080.0000 - val_root_mean_squared_error: 30496.1328\n",
            "Epoch 235/400\n",
            "35/35 [==============================] - 2s 54ms/step - loss: 1532574720.0000 - root_mean_squared_error: 39148.1133 - val_loss: 871291968.0000 - val_root_mean_squared_error: 29517.6543\n",
            "Epoch 236/400\n",
            "35/35 [==============================] - 2s 43ms/step - loss: 1547989376.0000 - root_mean_squared_error: 39344.4961 - val_loss: 879035008.0000 - val_root_mean_squared_error: 29648.5254\n",
            "Epoch 237/400\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 1641384192.0000 - root_mean_squared_error: 40514.0000 - val_loss: 827700032.0000 - val_root_mean_squared_error: 28769.7754\n",
            "Epoch 238/400\n",
            "35/35 [==============================] - 1s 37ms/step - loss: 1752671232.0000 - root_mean_squared_error: 41864.9141 - val_loss: 880913664.0000 - val_root_mean_squared_error: 29680.1895\n",
            "Epoch 239/400\n",
            "35/35 [==============================] - 2s 45ms/step - loss: 1464060032.0000 - root_mean_squared_error: 38263.0352 - val_loss: 939577408.0000 - val_root_mean_squared_error: 30652.5273\n",
            "Epoch 240/400\n",
            "35/35 [==============================] - 1s 35ms/step - loss: 1606558720.0000 - root_mean_squared_error: 40081.8984 - val_loss: 889929216.0000 - val_root_mean_squared_error: 29831.6816\n",
            "Epoch 241/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1411055104.0000 - root_mean_squared_error: 37564.0117 - val_loss: 933830720.0000 - val_root_mean_squared_error: 30558.6445\n",
            "Epoch 242/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1690707840.0000 - root_mean_squared_error: 41118.2188 - val_loss: 966403392.0000 - val_root_mean_squared_error: 31087.0293\n",
            "Epoch 243/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1456774272.0000 - root_mean_squared_error: 38167.7109 - val_loss: 969707840.0000 - val_root_mean_squared_error: 31140.1309\n",
            "Epoch 244/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1596376320.0000 - root_mean_squared_error: 39954.6758 - val_loss: 943688128.0000 - val_root_mean_squared_error: 30719.5059\n",
            "Epoch 245/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1600037504.0000 - root_mean_squared_error: 40000.4688 - val_loss: 898046464.0000 - val_root_mean_squared_error: 29967.4238\n",
            "Epoch 246/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1503633664.0000 - root_mean_squared_error: 38776.7148 - val_loss: 889517184.0000 - val_root_mean_squared_error: 29824.7734\n",
            "Epoch 247/400\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 1590231680.0000 - root_mean_squared_error: 39877.7109 - val_loss: 874917696.0000 - val_root_mean_squared_error: 29579.0078\n",
            "Epoch 248/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1439273088.0000 - root_mean_squared_error: 37937.7539 - val_loss: 883154240.0000 - val_root_mean_squared_error: 29717.9102\n",
            "Epoch 249/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1466421632.0000 - root_mean_squared_error: 38293.8828 - val_loss: 877201408.0000 - val_root_mean_squared_error: 29617.5859\n",
            "Epoch 250/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1550913664.0000 - root_mean_squared_error: 39381.6406 - val_loss: 906022080.0000 - val_root_mean_squared_error: 30100.2012\n",
            "Epoch 251/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1609255808.0000 - root_mean_squared_error: 40115.5312 - val_loss: 895609600.0000 - val_root_mean_squared_error: 29926.7383\n",
            "Epoch 252/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1505558144.0000 - root_mean_squared_error: 38801.5234 - val_loss: 862329408.0000 - val_root_mean_squared_error: 29365.4453\n",
            "Epoch 253/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1543597824.0000 - root_mean_squared_error: 39288.6484 - val_loss: 928571328.0000 - val_root_mean_squared_error: 30472.4688\n",
            "Epoch 254/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1399211392.0000 - root_mean_squared_error: 37406.0352 - val_loss: 946969280.0000 - val_root_mean_squared_error: 30772.8652\n",
            "Epoch 255/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1285932800.0000 - root_mean_squared_error: 35859.9062 - val_loss: 856847232.0000 - val_root_mean_squared_error: 29271.9531\n",
            "Epoch 256/400\n",
            "35/35 [==============================] - 1s 18ms/step - loss: 1513840128.0000 - root_mean_squared_error: 38908.0977 - val_loss: 821425728.0000 - val_root_mean_squared_error: 28660.5254\n",
            "Epoch 257/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1396412032.0000 - root_mean_squared_error: 37368.5977 - val_loss: 836815360.0000 - val_root_mean_squared_error: 28927.7617\n",
            "Epoch 258/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1510111872.0000 - root_mean_squared_error: 38860.1562 - val_loss: 767037184.0000 - val_root_mean_squared_error: 27695.4355\n",
            "Epoch 259/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1397557888.0000 - root_mean_squared_error: 37383.9258 - val_loss: 785861632.0000 - val_root_mean_squared_error: 28033.2227\n",
            "Epoch 260/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1685357824.0000 - root_mean_squared_error: 41053.1094 - val_loss: 808463744.0000 - val_root_mean_squared_error: 28433.4961\n",
            "Epoch 261/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1627617152.0000 - root_mean_squared_error: 40343.7383 - val_loss: 824692928.0000 - val_root_mean_squared_error: 28717.4668\n",
            "Epoch 262/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1394312064.0000 - root_mean_squared_error: 37340.4883 - val_loss: 816321920.0000 - val_root_mean_squared_error: 28571.3477\n",
            "Epoch 263/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1579255424.0000 - root_mean_squared_error: 39739.8477 - val_loss: 854919552.0000 - val_root_mean_squared_error: 29239.0078\n",
            "Epoch 264/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1600243328.0000 - root_mean_squared_error: 40003.0391 - val_loss: 844906176.0000 - val_root_mean_squared_error: 29067.2695\n",
            "Epoch 265/400\n",
            "35/35 [==============================] - 1s 28ms/step - loss: 1671724800.0000 - root_mean_squared_error: 40886.7305 - val_loss: 811336640.0000 - val_root_mean_squared_error: 28483.9707\n",
            "Epoch 266/400\n",
            "35/35 [==============================] - 1s 27ms/step - loss: 1580547456.0000 - root_mean_squared_error: 39756.0977 - val_loss: 912770432.0000 - val_root_mean_squared_error: 30212.0918\n",
            "Epoch 267/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1451866112.0000 - root_mean_squared_error: 38103.3594 - val_loss: 841663232.0000 - val_root_mean_squared_error: 29011.4336\n",
            "Epoch 268/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1627848192.0000 - root_mean_squared_error: 40346.6016 - val_loss: 778983808.0000 - val_root_mean_squared_error: 27910.2812\n",
            "Epoch 269/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1584060800.0000 - root_mean_squared_error: 39800.2617 - val_loss: 787749696.0000 - val_root_mean_squared_error: 28066.8789\n",
            "Epoch 270/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1373583744.0000 - root_mean_squared_error: 37061.8906 - val_loss: 804775616.0000 - val_root_mean_squared_error: 28368.5664\n",
            "Epoch 271/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1537863552.0000 - root_mean_squared_error: 39215.6016 - val_loss: 838380928.0000 - val_root_mean_squared_error: 28954.8086\n",
            "Epoch 272/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1496911360.0000 - root_mean_squared_error: 38689.9375 - val_loss: 817255040.0000 - val_root_mean_squared_error: 28587.6719\n",
            "Epoch 273/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1562721920.0000 - root_mean_squared_error: 39531.2773 - val_loss: 795805056.0000 - val_root_mean_squared_error: 28210.0176\n",
            "Epoch 274/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1497889280.0000 - root_mean_squared_error: 38702.5742 - val_loss: 855464128.0000 - val_root_mean_squared_error: 29248.3184\n",
            "Epoch 275/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1543383808.0000 - root_mean_squared_error: 39285.9258 - val_loss: 866345280.0000 - val_root_mean_squared_error: 29433.7441\n",
            "Epoch 276/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1364179712.0000 - root_mean_squared_error: 36934.8047 - val_loss: 859141760.0000 - val_root_mean_squared_error: 29311.1191\n",
            "Epoch 277/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1322864896.0000 - root_mean_squared_error: 36371.2109 - val_loss: 840338880.0000 - val_root_mean_squared_error: 28988.5996\n",
            "Epoch 278/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1653929984.0000 - root_mean_squared_error: 40668.5391 - val_loss: 889933120.0000 - val_root_mean_squared_error: 29831.7461\n",
            "Epoch 279/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1560180992.0000 - root_mean_squared_error: 39499.1250 - val_loss: 902827776.0000 - val_root_mean_squared_error: 30047.0918\n",
            "Epoch 280/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1424761856.0000 - root_mean_squared_error: 37746.0156 - val_loss: 939358848.0000 - val_root_mean_squared_error: 30648.9609\n",
            "Epoch 281/400\n",
            "35/35 [==============================] - 1s 30ms/step - loss: 1674895872.0000 - root_mean_squared_error: 40925.4922 - val_loss: 922599744.0000 - val_root_mean_squared_error: 30374.3262\n",
            "Epoch 282/400\n",
            "35/35 [==============================] - 1s 33ms/step - loss: 1459769344.0000 - root_mean_squared_error: 38206.9258 - val_loss: 962054912.0000 - val_root_mean_squared_error: 31017.0098\n",
            "Epoch 283/400\n",
            "35/35 [==============================] - 1s 26ms/step - loss: 1683809664.0000 - root_mean_squared_error: 41034.2500 - val_loss: 934198016.0000 - val_root_mean_squared_error: 30564.6523\n",
            "Epoch 284/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1687754880.0000 - root_mean_squared_error: 41082.2930 - val_loss: 976986816.0000 - val_root_mean_squared_error: 31256.7871\n",
            "Epoch 285/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1631788416.0000 - root_mean_squared_error: 40395.3984 - val_loss: 906280640.0000 - val_root_mean_squared_error: 30104.4941\n",
            "Epoch 286/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1485035008.0000 - root_mean_squared_error: 38536.1523 - val_loss: 824984576.0000 - val_root_mean_squared_error: 28722.5449\n",
            "Epoch 287/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1360124160.0000 - root_mean_squared_error: 36879.8594 - val_loss: 820379904.0000 - val_root_mean_squared_error: 28642.2754\n",
            "Epoch 288/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1596024704.0000 - root_mean_squared_error: 39950.2773 - val_loss: 908115264.0000 - val_root_mean_squared_error: 30134.9512\n",
            "Epoch 289/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1526120192.0000 - root_mean_squared_error: 39065.5859 - val_loss: 932261696.0000 - val_root_mean_squared_error: 30532.9609\n",
            "Epoch 290/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1476432256.0000 - root_mean_squared_error: 38424.3711 - val_loss: 909646528.0000 - val_root_mean_squared_error: 30160.3457\n",
            "Epoch 291/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1504016512.0000 - root_mean_squared_error: 38781.6523 - val_loss: 932609088.0000 - val_root_mean_squared_error: 30538.6504\n",
            "Epoch 292/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1472352384.0000 - root_mean_squared_error: 38371.2461 - val_loss: 883814016.0000 - val_root_mean_squared_error: 29729.0098\n",
            "Epoch 293/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1394099840.0000 - root_mean_squared_error: 37337.6445 - val_loss: 925985088.0000 - val_root_mean_squared_error: 30430.0020\n",
            "Epoch 294/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1507515008.0000 - root_mean_squared_error: 38826.7305 - val_loss: 910879232.0000 - val_root_mean_squared_error: 30180.7754\n",
            "Epoch 295/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1497106816.0000 - root_mean_squared_error: 38692.4648 - val_loss: 937873600.0000 - val_root_mean_squared_error: 30624.7227\n",
            "Epoch 296/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1470472576.0000 - root_mean_squared_error: 38346.7422 - val_loss: 988105472.0000 - val_root_mean_squared_error: 31434.1445\n",
            "Epoch 297/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1308509568.0000 - root_mean_squared_error: 36173.3242 - val_loss: 969120448.0000 - val_root_mean_squared_error: 31130.6992\n",
            "Epoch 298/400\n",
            "35/35 [==============================] - 1s 32ms/step - loss: 1509405824.0000 - root_mean_squared_error: 38851.0742 - val_loss: 925441664.0000 - val_root_mean_squared_error: 30421.0723\n",
            "Epoch 299/400\n",
            "35/35 [==============================] - 1s 31ms/step - loss: 1561113600.0000 - root_mean_squared_error: 39510.9297 - val_loss: 920399424.0000 - val_root_mean_squared_error: 30338.0859\n",
            "Epoch 300/400\n",
            "35/35 [==============================] - 1s 24ms/step - loss: 1564229504.0000 - root_mean_squared_error: 39550.3398 - val_loss: 944977216.0000 - val_root_mean_squared_error: 30740.4805\n",
            "Epoch 301/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1436721792.0000 - root_mean_squared_error: 37904.1133 - val_loss: 997608192.0000 - val_root_mean_squared_error: 31584.9355\n",
            "Epoch 302/400\n",
            "35/35 [==============================] - 1s 20ms/step - loss: 1562583168.0000 - root_mean_squared_error: 39529.5234 - val_loss: 956517760.0000 - val_root_mean_squared_error: 30927.6211\n",
            "Epoch 303/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1466299648.0000 - root_mean_squared_error: 38292.2930 - val_loss: 940536384.0000 - val_root_mean_squared_error: 30668.1641\n",
            "Epoch 304/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1578630272.0000 - root_mean_squared_error: 39731.9805 - val_loss: 900515008.0000 - val_root_mean_squared_error: 30008.5820\n",
            "Epoch 305/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1567862912.0000 - root_mean_squared_error: 39596.2500 - val_loss: 898453760.0000 - val_root_mean_squared_error: 29974.2168\n",
            "Epoch 306/400\n",
            "35/35 [==============================] - 1s 19ms/step - loss: 1426817152.0000 - root_mean_squared_error: 37773.2305 - val_loss: 928096512.0000 - val_root_mean_squared_error: 30464.6758\n",
            "Epoch 307/400\n",
            "35/35 [==============================] - 1s 21ms/step - loss: 1421950208.0000 - root_mean_squared_error: 37708.7539 - val_loss: 965018496.0000 - val_root_mean_squared_error: 31064.7461\n",
            "Epoch 308/400\n",
            "35/35 [==============================] - 1s 23ms/step - loss: 1630517632.0000 - root_mean_squared_error: 40379.6680 - val_loss: 1007473408.0000 - val_root_mean_squared_error: 31740.7207\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7978a0100550>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We got around 21000 or 22000 in validation error, so it's better than conventional Machine Learning algorithm. But I'm not sure, maybe that's just an accident(variations during train-val split, sheer luck). We will come to hyperparameter tuning phase to see more on how we can fine-tune the model to get optimal result.**"
      ],
      "metadata": {
        "id": "uIa7FcSkzbQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note that the evaluation results may vary greatly in different notebook running attempts, because of the random nature of the train-val dataset splitting process. The dataset being so small is also a contributing factor.The great variance of the result we get here can be mitigated if we can apply k-fold cross-validation just like in scikit-learn's regular ML algorithm. So if you run the notebook, you may not get the evaluation result I got above.**"
      ],
      "metadata": {
        "id": "1kWpRjRTnscL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([num_valid] + cat_valid_1, price_valid) #evaluation on validation data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhYHFBSr3TCc",
        "outputId": "ca6b0933-0388-40f7-db8b-ca8a71244190"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 12ms/step - loss: 767037184.0000 - root_mean_squared_error: 27695.4355\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[767037184.0, 27695.435546875]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We try a technique of hyperparameter tuning in Deep Learing using the new library provided by Keras: keras_tuner.**"
      ],
      "metadata": {
        "id": "BZJblWv33CjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "G8tx5_mq3xc1"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we separate the two processes: model construction and hyperparameter space specification, into 2 different functions. The first function(\"call_existing_code\") will build the model, along with all the hyperparameters later to be filled by hyperparemeter ranges. Then the second function(\"build_hyper_model\") will specify all the hyperparameter ranges for different parts of the model(number of dense layers, use Dropout or not, number of neurons for each dense layer, kernel initializer,...), and after that, calling the first function with hyperparameter ranges to return the completed Keras model ready to be fine-tuned by hyperparameter optimization algorithm. The second function as only one argument \"hp\", as you will see later that is required by keras_tuner library during the optimization process.**"
      ],
      "metadata": {
        "id": "ZIVaIXiT11SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_existing_code(num_input, cat_inputs, concat_input, num_layers, units, activation, kernel_initializer, dropout, lr):\n",
        "\n",
        "    dense_1 = keras.layers.Dropout(0.25)(concat_input)\n",
        "    for i in range(num_layers): #num of dense layers\n",
        "        dense_1 = keras.layers.Dense(units = units, activation = activation, kernel_initializer = kernel_initializer)(dense_1)\n",
        "        if dropout:\n",
        "            dense_1 = keras.layers.Dropout(0.25)(dense_1)\n",
        "\n",
        "    output = keras.layers.Dense(1)(dense_1)\n",
        "\n",
        "    model = keras.models.Model(inputs = [num_input] + cat_inputs, outputs = [output])#complete model\n",
        "    model.compile(\n",
        "        optimizer = keras.optimizers.Nadam(learning_rate = lr),\n",
        "        loss = \"mse\",\n",
        "        metrics = [keras.metrics.RootMeanSquaredError()],\n",
        "    )#compliing the model.\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_hyper_model(hp):\n",
        "    num_layers = hp.Int(\"num_layers\", 1, 3) #range of selection for number of dense layers.\n",
        "    units = hp.Int(\"units\", min_value = 16, max_value = 128, step = 16) #number of neurons\n",
        "    activation = hp.Choice(\"activation\", [\"relu\", \"selu\", \"elu\"]) #activation functions to use\n",
        "    kernel_initializer = hp.Choice(\"kernel_initializer\", [\"glorot_uniform\", \"he_normal\", \"lecun_normal\"])#kernal initilizer\n",
        "    dropout = hp.Boolean(\"dropout\")#whether to use Dropout or not.\n",
        "    lr = hp.Float(\"lr\", min_value = 1e-2, max_value = 0.2, sampling = \"log\")#learning rate.\n",
        "\n",
        "    model = call_existing_code(num_input, cat_inputs, concat_input, num_layers = num_layers,\n",
        "        units = units, activation = activation, kernel_initializer = kernel_initializer, dropout = dropout, lr = lr)#call the model.\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "o2ODnxlK58kN"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**specifying which hyperparameter optimization algorithm to use. In this case we use Hyperband algorithm. You pass the function \"build_hyper_model\" into the function keras_tuner.Hyperband, and the rest are hyperparameters used for optimization process. During training the detail records of optimization process would be saved into the specified directory \"hyperband_test\" in your working environment, which you can view using Tensorboard.**"
      ],
      "metadata": {
        "id": "5dTsOswy4HUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: hyperparameter tuning with Hyperband optimization algorithm can take extremely long, so whenever you don't feel the model can improve more, just cancel the below code cell.**"
      ],
      "metadata": {
        "id": "RnEggAztidKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperband_tuner = keras_tuner.Hyperband(\n",
        "    hypermodel = build_hyper_model,\n",
        "    objective = keras_tuner.Objective(\"val_root_mean_squared_error\", direction = \"min\"),\n",
        "    max_epochs = 100,\n",
        "    executions_per_trial = 2,\n",
        "    overwrite = True,\n",
        "    directory = DATASET_ROOT_DIR,\n",
        "    project_name = \"hyperband_test\",\n",
        "    max_consecutive_failed_trials = 3,\n",
        "    seed = 42\n",
        ")#hyperband algorithm.\n",
        "\n",
        "hyperband_tuner.search(x = [num_train] + cat_train_1, y = price_train,\n",
        "                       validation_data = ([num_valid] + cat_valid_1, price_valid))#call search() to start searching for optimal hyperparameters combination"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "pqp1NM-jEa39",
        "outputId": "f08ee389-cc53-4b79-d4f4-934a87b80acb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 104 Complete [00h 00m 13s]\n",
            "val_root_mean_squared_error: 38640.73828125\n",
            "\n",
            "Best val_root_mean_squared_error So Far: 37007.7890625\n",
            "Total elapsed time: 00h 26m 01s\n",
            "\n",
            "Search: Running Trial #105\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "3                 |2                 |num_layers\n",
            "64                |64                |units\n",
            "elu               |selu              |activation\n",
            "lecun_normal      |he_normal         |kernel_initializer\n",
            "True              |True              |dropout\n",
            "0.013394          |0.030357          |lr\n",
            "4                 |4                 |tuner/epochs\n",
            "2                 |2                 |tuner/initial_epoch\n",
            "4                 |4                 |tuner/bracket\n",
            "1                 |1                 |tuner/round\n",
            "0051              |0058              |tuner/trial_id\n",
            "\n",
            "Epoch 3/4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-5d5aa482fbb9>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m )#hyperband algorithm.\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m hyperband_tuner.search(x = [num_train] + cat_train_1, y = price_train,\n\u001b[0m\u001b[1;32m     14\u001b[0m                        validation_data = ([num_valid] + cat_valid_1, price_valid))#call search() to start searching for optimal hyperparameters combination\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = hyperband_tuner.get_best_models() #get the best model.\n",
        "best_model = models[0]\n",
        "# Build the model.\n",
        "# Needed for `Sequential` without specified `input_shape`.\n",
        "best_model.build(input_shape = (None, 343))\n",
        "#best_model.summary()"
      ],
      "metadata": {
        "id": "F4jM585xZHye"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After getting the best combination of hyperparameters for the task, now we will retrain the model using the whole training set (train set + val set) using the best founded hyperparameters. By that we repeat the process which has been done in regular Machine Learning part using scikit_learn's Randomized Search function: looking for the best hyperparameters using cross-validation, then retrain the model with the whole training set.**"
      ],
      "metadata": {
        "id": "aRR7lk3w5QA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = \"root_mean_squared_error\", patience = 50, restore_best_weights = True)\n",
        "\n",
        "cat_train_2 = np.hsplit(cat_train_data, 43)\n",
        "\n",
        "best_hps = hyperband_tuner.get_best_hyperparameters()\n",
        "# Build the model with the best hp.\n",
        "model = build_hyper_model(best_hps[0])\n",
        "\n",
        "model.fit(x = [num_train_data] + cat_train_2, y = train_labels.to_numpy(), epochs = 400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLMSWlfXZeG8",
        "outputId": "1858acdc-b8c7-4aa1-901a-dfac88e1371e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "46/46 [==============================] - 4s 15ms/step - loss: 26090366976.0000 - root_mean_squared_error: 161525.1250\n",
            "Epoch 2/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 3087390208.0000 - root_mean_squared_error: 55564.2891\n",
            "Epoch 3/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2340731392.0000 - root_mean_squared_error: 48381.1055\n",
            "Epoch 4/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2438410752.0000 - root_mean_squared_error: 49380.2656\n",
            "Epoch 5/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2545708288.0000 - root_mean_squared_error: 50455.0117\n",
            "Epoch 6/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2216658432.0000 - root_mean_squared_error: 47081.4023\n",
            "Epoch 7/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2145791616.0000 - root_mean_squared_error: 46322.6914\n",
            "Epoch 8/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2218016768.0000 - root_mean_squared_error: 47095.8242\n",
            "Epoch 9/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 2292818176.0000 - root_mean_squared_error: 47883.3789\n",
            "Epoch 10/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1974253312.0000 - root_mean_squared_error: 44432.5703\n",
            "Epoch 11/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1933636224.0000 - root_mean_squared_error: 43973.1289\n",
            "Epoch 12/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 2206503168.0000 - root_mean_squared_error: 46973.4297\n",
            "Epoch 13/400\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1993849728.0000 - root_mean_squared_error: 44652.5430\n",
            "Epoch 14/400\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 2201128192.0000 - root_mean_squared_error: 46916.1836\n",
            "Epoch 15/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 2158062336.0000 - root_mean_squared_error: 46454.9492\n",
            "Epoch 16/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1937130624.0000 - root_mean_squared_error: 44012.8438\n",
            "Epoch 17/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1984166528.0000 - root_mean_squared_error: 44543.9844\n",
            "Epoch 18/400\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 2070772352.0000 - root_mean_squared_error: 45505.7383\n",
            "Epoch 19/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1963374848.0000 - root_mean_squared_error: 44309.9844\n",
            "Epoch 20/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1993166976.0000 - root_mean_squared_error: 44644.8984\n",
            "Epoch 21/400\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 1959713664.0000 - root_mean_squared_error: 44268.6523\n",
            "Epoch 22/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 2090825344.0000 - root_mean_squared_error: 45725.5430\n",
            "Epoch 23/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1838685568.0000 - root_mean_squared_error: 42879.8984\n",
            "Epoch 24/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1722755584.0000 - root_mean_squared_error: 41506.0898\n",
            "Epoch 25/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1898166784.0000 - root_mean_squared_error: 43567.9531\n",
            "Epoch 26/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1644513280.0000 - root_mean_squared_error: 40552.5977\n",
            "Epoch 27/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1703226624.0000 - root_mean_squared_error: 41270.1641\n",
            "Epoch 28/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1683598592.0000 - root_mean_squared_error: 41031.6758\n",
            "Epoch 29/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1677011328.0000 - root_mean_squared_error: 40951.3281\n",
            "Epoch 30/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1740811776.0000 - root_mean_squared_error: 41723.0391\n",
            "Epoch 31/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1625875840.0000 - root_mean_squared_error: 40322.1484\n",
            "Epoch 32/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1397684992.0000 - root_mean_squared_error: 37385.6250\n",
            "Epoch 33/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1600201344.0000 - root_mean_squared_error: 40002.5156\n",
            "Epoch 34/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1589850752.0000 - root_mean_squared_error: 39872.9336\n",
            "Epoch 35/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1599878272.0000 - root_mean_squared_error: 39998.4766\n",
            "Epoch 36/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1525981824.0000 - root_mean_squared_error: 39063.8164\n",
            "Epoch 37/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1473594752.0000 - root_mean_squared_error: 38387.4297\n",
            "Epoch 38/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1681242112.0000 - root_mean_squared_error: 41002.9531\n",
            "Epoch 39/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1369308672.0000 - root_mean_squared_error: 37004.1719\n",
            "Epoch 40/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1622256768.0000 - root_mean_squared_error: 40277.2500\n",
            "Epoch 41/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1430491904.0000 - root_mean_squared_error: 37821.8438\n",
            "Epoch 42/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1717396608.0000 - root_mean_squared_error: 41441.4844\n",
            "Epoch 43/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1639020672.0000 - root_mean_squared_error: 40484.8203\n",
            "Epoch 44/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1572261248.0000 - root_mean_squared_error: 39651.7500\n",
            "Epoch 45/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1351713408.0000 - root_mean_squared_error: 36765.6562\n",
            "Epoch 46/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1339366784.0000 - root_mean_squared_error: 36597.3594\n",
            "Epoch 47/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1446060032.0000 - root_mean_squared_error: 38027.0938\n",
            "Epoch 48/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1387566464.0000 - root_mean_squared_error: 37250.0547\n",
            "Epoch 49/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1391074560.0000 - root_mean_squared_error: 37297.1133\n",
            "Epoch 50/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1619879040.0000 - root_mean_squared_error: 40247.7188\n",
            "Epoch 51/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1457907200.0000 - root_mean_squared_error: 38182.5508\n",
            "Epoch 52/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1403435136.0000 - root_mean_squared_error: 37462.4492\n",
            "Epoch 53/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1383710720.0000 - root_mean_squared_error: 37198.2617\n",
            "Epoch 54/400\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 1347012736.0000 - root_mean_squared_error: 36701.6719\n",
            "Epoch 55/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1449290880.0000 - root_mean_squared_error: 38069.5508\n",
            "Epoch 56/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1312619520.0000 - root_mean_squared_error: 36230.0898\n",
            "Epoch 57/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1480130688.0000 - root_mean_squared_error: 38472.4648\n",
            "Epoch 58/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1371120256.0000 - root_mean_squared_error: 37028.6406\n",
            "Epoch 59/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1489565312.0000 - root_mean_squared_error: 38594.8867\n",
            "Epoch 60/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1392655488.0000 - root_mean_squared_error: 37318.2969\n",
            "Epoch 61/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1408613760.0000 - root_mean_squared_error: 37531.5039\n",
            "Epoch 62/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1314148736.0000 - root_mean_squared_error: 36251.1875\n",
            "Epoch 63/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1378276352.0000 - root_mean_squared_error: 37125.1445\n",
            "Epoch 64/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1326120832.0000 - root_mean_squared_error: 36415.9414\n",
            "Epoch 65/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1281331200.0000 - root_mean_squared_error: 35795.6875\n",
            "Epoch 66/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1379732864.0000 - root_mean_squared_error: 37144.7539\n",
            "Epoch 67/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1373690752.0000 - root_mean_squared_error: 37063.3320\n",
            "Epoch 68/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1354063488.0000 - root_mean_squared_error: 36797.6016\n",
            "Epoch 69/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1361501824.0000 - root_mean_squared_error: 36898.5352\n",
            "Epoch 70/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1247533952.0000 - root_mean_squared_error: 35320.4453\n",
            "Epoch 71/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1310909824.0000 - root_mean_squared_error: 36206.4883\n",
            "Epoch 72/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1368335616.0000 - root_mean_squared_error: 36991.0195\n",
            "Epoch 73/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1362456832.0000 - root_mean_squared_error: 36911.4727\n",
            "Epoch 74/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1365944960.0000 - root_mean_squared_error: 36958.6914\n",
            "Epoch 75/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1489099008.0000 - root_mean_squared_error: 38588.8438\n",
            "Epoch 76/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1394604544.0000 - root_mean_squared_error: 37344.4023\n",
            "Epoch 77/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1209149312.0000 - root_mean_squared_error: 34772.8242\n",
            "Epoch 78/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1344609408.0000 - root_mean_squared_error: 36668.9141\n",
            "Epoch 79/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1215505664.0000 - root_mean_squared_error: 34864.1016\n",
            "Epoch 80/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1370142720.0000 - root_mean_squared_error: 37015.4375\n",
            "Epoch 81/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1445144320.0000 - root_mean_squared_error: 38015.0508\n",
            "Epoch 82/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1187148544.0000 - root_mean_squared_error: 34455.0234\n",
            "Epoch 83/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1476006400.0000 - root_mean_squared_error: 38418.8281\n",
            "Epoch 84/400\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 1248216320.0000 - root_mean_squared_error: 35330.1055\n",
            "Epoch 85/400\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 1421041664.0000 - root_mean_squared_error: 37696.7070\n",
            "Epoch 86/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1293870976.0000 - root_mean_squared_error: 35970.4180\n",
            "Epoch 87/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1280277632.0000 - root_mean_squared_error: 35780.9648\n",
            "Epoch 88/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1189921152.0000 - root_mean_squared_error: 34495.2344\n",
            "Epoch 89/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1334651392.0000 - root_mean_squared_error: 36532.8789\n",
            "Epoch 90/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1274291328.0000 - root_mean_squared_error: 35697.2188\n",
            "Epoch 91/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1336304128.0000 - root_mean_squared_error: 36555.4922\n",
            "Epoch 92/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1350959616.0000 - root_mean_squared_error: 36755.4023\n",
            "Epoch 93/400\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 1298387072.0000 - root_mean_squared_error: 36033.1367\n",
            "Epoch 94/400\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 1198956416.0000 - root_mean_squared_error: 34625.9492\n",
            "Epoch 95/400\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 1339040512.0000 - root_mean_squared_error: 36592.9023\n",
            "Epoch 96/400\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 1364898688.0000 - root_mean_squared_error: 36944.5352\n",
            "Epoch 97/400\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 1278018560.0000 - root_mean_squared_error: 35749.3828\n",
            "Epoch 98/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1261749248.0000 - root_mean_squared_error: 35521.1094\n",
            "Epoch 99/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1389867264.0000 - root_mean_squared_error: 37280.9219\n",
            "Epoch 100/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1324366720.0000 - root_mean_squared_error: 36391.8477\n",
            "Epoch 101/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1235915904.0000 - root_mean_squared_error: 35155.5938\n",
            "Epoch 102/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1244011392.0000 - root_mean_squared_error: 35270.5430\n",
            "Epoch 103/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1366730368.0000 - root_mean_squared_error: 36969.3164\n",
            "Epoch 104/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1253415296.0000 - root_mean_squared_error: 35403.6055\n",
            "Epoch 105/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1353750656.0000 - root_mean_squared_error: 36793.3516\n",
            "Epoch 106/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1300063360.0000 - root_mean_squared_error: 36056.3906\n",
            "Epoch 107/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1229632384.0000 - root_mean_squared_error: 35066.1133\n",
            "Epoch 108/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1845434880.0000 - root_mean_squared_error: 42958.5273\n",
            "Epoch 109/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1299119360.0000 - root_mean_squared_error: 36043.2969\n",
            "Epoch 110/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1222042368.0000 - root_mean_squared_error: 34957.7227\n",
            "Epoch 111/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1387057408.0000 - root_mean_squared_error: 37243.2188\n",
            "Epoch 112/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1334524160.0000 - root_mean_squared_error: 36531.1406\n",
            "Epoch 113/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1256603008.0000 - root_mean_squared_error: 35448.5977\n",
            "Epoch 114/400\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 1373592064.0000 - root_mean_squared_error: 37062.0039\n",
            "Epoch 115/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1215130240.0000 - root_mean_squared_error: 34858.7188\n",
            "Epoch 116/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1236528256.0000 - root_mean_squared_error: 35164.3047\n",
            "Epoch 117/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1329416192.0000 - root_mean_squared_error: 36461.1602\n",
            "Epoch 118/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1414552064.0000 - root_mean_squared_error: 37610.5312\n",
            "Epoch 119/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1249214592.0000 - root_mean_squared_error: 35344.2305\n",
            "Epoch 120/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1303224448.0000 - root_mean_squared_error: 36100.1992\n",
            "Epoch 121/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1177880832.0000 - root_mean_squared_error: 34320.2695\n",
            "Epoch 122/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1171674624.0000 - root_mean_squared_error: 34229.7344\n",
            "Epoch 123/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1766209024.0000 - root_mean_squared_error: 42026.2891\n",
            "Epoch 124/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1247001344.0000 - root_mean_squared_error: 35312.9062\n",
            "Epoch 125/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1227697152.0000 - root_mean_squared_error: 35038.5078\n",
            "Epoch 126/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1267797120.0000 - root_mean_squared_error: 35606.1367\n",
            "Epoch 127/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1268110976.0000 - root_mean_squared_error: 35610.5469\n",
            "Epoch 128/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1275109376.0000 - root_mean_squared_error: 35708.6719\n",
            "Epoch 129/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1176305920.0000 - root_mean_squared_error: 34297.3164\n",
            "Epoch 130/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1441778944.0000 - root_mean_squared_error: 37970.7656\n",
            "Epoch 131/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1226154496.0000 - root_mean_squared_error: 35016.4883\n",
            "Epoch 132/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1227648896.0000 - root_mean_squared_error: 35037.8203\n",
            "Epoch 133/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1161516288.0000 - root_mean_squared_error: 34081.0234\n",
            "Epoch 134/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1139975552.0000 - root_mean_squared_error: 33763.5234\n",
            "Epoch 135/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1398649984.0000 - root_mean_squared_error: 37398.5273\n",
            "Epoch 136/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1223361408.0000 - root_mean_squared_error: 34976.5820\n",
            "Epoch 137/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1353522816.0000 - root_mean_squared_error: 36790.2539\n",
            "Epoch 138/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1267281920.0000 - root_mean_squared_error: 35598.9023\n",
            "Epoch 139/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1854333568.0000 - root_mean_squared_error: 43061.9727\n",
            "Epoch 140/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1134814848.0000 - root_mean_squared_error: 33687.0117\n",
            "Epoch 141/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1160522752.0000 - root_mean_squared_error: 34066.4453\n",
            "Epoch 142/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1469867776.0000 - root_mean_squared_error: 38338.8555\n",
            "Epoch 143/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1272873984.0000 - root_mean_squared_error: 35677.3594\n",
            "Epoch 144/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1252599040.0000 - root_mean_squared_error: 35392.0742\n",
            "Epoch 145/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1286173184.0000 - root_mean_squared_error: 35863.2578\n",
            "Epoch 146/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1250526720.0000 - root_mean_squared_error: 35362.7852\n",
            "Epoch 147/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1264391552.0000 - root_mean_squared_error: 35558.2812\n",
            "Epoch 148/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1222962176.0000 - root_mean_squared_error: 34970.8750\n",
            "Epoch 149/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1326298368.0000 - root_mean_squared_error: 36418.3789\n",
            "Epoch 150/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1288783104.0000 - root_mean_squared_error: 35899.6250\n",
            "Epoch 151/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1299029248.0000 - root_mean_squared_error: 36042.0469\n",
            "Epoch 152/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1480558848.0000 - root_mean_squared_error: 38478.0312\n",
            "Epoch 153/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1261593600.0000 - root_mean_squared_error: 35518.9180\n",
            "Epoch 154/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1268512256.0000 - root_mean_squared_error: 35616.1797\n",
            "Epoch 155/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1169411200.0000 - root_mean_squared_error: 34196.6562\n",
            "Epoch 156/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1275227392.0000 - root_mean_squared_error: 35710.3242\n",
            "Epoch 157/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1277500288.0000 - root_mean_squared_error: 35742.1367\n",
            "Epoch 158/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1217239296.0000 - root_mean_squared_error: 34888.9570\n",
            "Epoch 159/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1148167296.0000 - root_mean_squared_error: 33884.6172\n",
            "Epoch 160/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1376433152.0000 - root_mean_squared_error: 37100.3125\n",
            "Epoch 161/400\n",
            "46/46 [==============================] - 1s 13ms/step - loss: 1271508736.0000 - root_mean_squared_error: 35658.2227\n",
            "Epoch 162/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1319625344.0000 - root_mean_squared_error: 36326.6484\n",
            "Epoch 163/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1203912832.0000 - root_mean_squared_error: 34697.4453\n",
            "Epoch 164/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1134539520.0000 - root_mean_squared_error: 33682.9258\n",
            "Epoch 165/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1252256896.0000 - root_mean_squared_error: 35387.2422\n",
            "Epoch 166/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1239594496.0000 - root_mean_squared_error: 35207.8750\n",
            "Epoch 167/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1151041664.0000 - root_mean_squared_error: 33927.0039\n",
            "Epoch 168/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1193999616.0000 - root_mean_squared_error: 34554.2969\n",
            "Epoch 169/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1237186432.0000 - root_mean_squared_error: 35173.6602\n",
            "Epoch 170/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1277857664.0000 - root_mean_squared_error: 35747.1328\n",
            "Epoch 171/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1365768320.0000 - root_mean_squared_error: 36956.3008\n",
            "Epoch 172/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1165206144.0000 - root_mean_squared_error: 34135.1172\n",
            "Epoch 173/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1238023680.0000 - root_mean_squared_error: 35185.5586\n",
            "Epoch 174/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1172292352.0000 - root_mean_squared_error: 34238.7539\n",
            "Epoch 175/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1222815360.0000 - root_mean_squared_error: 34968.7773\n",
            "Epoch 176/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1132063872.0000 - root_mean_squared_error: 33646.1562\n",
            "Epoch 177/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1120860800.0000 - root_mean_squared_error: 33479.2578\n",
            "Epoch 178/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1012235840.0000 - root_mean_squared_error: 31815.6543\n",
            "Epoch 179/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1235387008.0000 - root_mean_squared_error: 35148.0703\n",
            "Epoch 180/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1225372544.0000 - root_mean_squared_error: 35005.3203\n",
            "Epoch 181/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1230082944.0000 - root_mean_squared_error: 35072.5391\n",
            "Epoch 182/400\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1352597632.0000 - root_mean_squared_error: 36777.6797\n",
            "Epoch 183/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1304818304.0000 - root_mean_squared_error: 36122.2695\n",
            "Epoch 184/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1223877504.0000 - root_mean_squared_error: 34983.9609\n",
            "Epoch 185/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1155297664.0000 - root_mean_squared_error: 33989.6719\n",
            "Epoch 186/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1293801856.0000 - root_mean_squared_error: 35969.4570\n",
            "Epoch 187/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1158416896.0000 - root_mean_squared_error: 34035.5234\n",
            "Epoch 188/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1118734592.0000 - root_mean_squared_error: 33447.4883\n",
            "Epoch 189/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1260177920.0000 - root_mean_squared_error: 35498.9844\n",
            "Epoch 190/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1119670656.0000 - root_mean_squared_error: 33461.4805\n",
            "Epoch 191/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1254979200.0000 - root_mean_squared_error: 35425.6875\n",
            "Epoch 192/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1207327360.0000 - root_mean_squared_error: 34746.6172\n",
            "Epoch 193/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1286904832.0000 - root_mean_squared_error: 35873.4570\n",
            "Epoch 194/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1244412800.0000 - root_mean_squared_error: 35276.2344\n",
            "Epoch 195/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1106556800.0000 - root_mean_squared_error: 33264.9492\n",
            "Epoch 196/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1136042752.0000 - root_mean_squared_error: 33705.2344\n",
            "Epoch 197/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1137839488.0000 - root_mean_squared_error: 33731.8750\n",
            "Epoch 198/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1249952512.0000 - root_mean_squared_error: 35354.6680\n",
            "Epoch 199/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1244843008.0000 - root_mean_squared_error: 35282.3320\n",
            "Epoch 200/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1197742720.0000 - root_mean_squared_error: 34608.4180\n",
            "Epoch 201/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1273673088.0000 - root_mean_squared_error: 35688.5586\n",
            "Epoch 202/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1089907072.0000 - root_mean_squared_error: 33013.7383\n",
            "Epoch 203/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1180992000.0000 - root_mean_squared_error: 34365.5625\n",
            "Epoch 204/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1211081088.0000 - root_mean_squared_error: 34800.5898\n",
            "Epoch 205/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1345075584.0000 - root_mean_squared_error: 36675.2695\n",
            "Epoch 206/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1011783936.0000 - root_mean_squared_error: 31808.5508\n",
            "Epoch 207/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1274576640.0000 - root_mean_squared_error: 35701.2148\n",
            "Epoch 208/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1242486912.0000 - root_mean_squared_error: 35248.9258\n",
            "Epoch 209/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1158868096.0000 - root_mean_squared_error: 34042.1523\n",
            "Epoch 210/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1163134336.0000 - root_mean_squared_error: 34104.7539\n",
            "Epoch 211/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1167975936.0000 - root_mean_squared_error: 34175.6641\n",
            "Epoch 212/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1159603072.0000 - root_mean_squared_error: 34052.9453\n",
            "Epoch 213/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1233379328.0000 - root_mean_squared_error: 35119.5000\n",
            "Epoch 214/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1068560320.0000 - root_mean_squared_error: 32688.8398\n",
            "Epoch 215/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1192547200.0000 - root_mean_squared_error: 34533.2773\n",
            "Epoch 216/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1125001984.0000 - root_mean_squared_error: 33541.0469\n",
            "Epoch 217/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1173298560.0000 - root_mean_squared_error: 34253.4453\n",
            "Epoch 218/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1289049216.0000 - root_mean_squared_error: 35903.3320\n",
            "Epoch 219/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1142747008.0000 - root_mean_squared_error: 33804.5391\n",
            "Epoch 220/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1296832768.0000 - root_mean_squared_error: 36011.5625\n",
            "Epoch 221/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1088825728.0000 - root_mean_squared_error: 32997.3594\n",
            "Epoch 222/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1197734016.0000 - root_mean_squared_error: 34608.2930\n",
            "Epoch 223/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1195265280.0000 - root_mean_squared_error: 34572.6094\n",
            "Epoch 224/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1136196864.0000 - root_mean_squared_error: 33707.5195\n",
            "Epoch 225/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1283514624.0000 - root_mean_squared_error: 35826.1719\n",
            "Epoch 226/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1236687360.0000 - root_mean_squared_error: 35166.5664\n",
            "Epoch 227/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1088965504.0000 - root_mean_squared_error: 32999.4766\n",
            "Epoch 228/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1122417664.0000 - root_mean_squared_error: 33502.5039\n",
            "Epoch 229/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1379537152.0000 - root_mean_squared_error: 37142.1211\n",
            "Epoch 230/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1282985472.0000 - root_mean_squared_error: 35818.7852\n",
            "Epoch 231/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1145508608.0000 - root_mean_squared_error: 33845.3633\n",
            "Epoch 232/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 996967488.0000 - root_mean_squared_error: 31574.7910\n",
            "Epoch 233/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1089893120.0000 - root_mean_squared_error: 33013.5273\n",
            "Epoch 234/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1144379520.0000 - root_mean_squared_error: 33828.6758\n",
            "Epoch 235/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1157450112.0000 - root_mean_squared_error: 34021.3203\n",
            "Epoch 236/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1092586240.0000 - root_mean_squared_error: 33054.2930\n",
            "Epoch 237/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1108387712.0000 - root_mean_squared_error: 33292.4570\n",
            "Epoch 238/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1244589312.0000 - root_mean_squared_error: 35278.7344\n",
            "Epoch 239/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1135066752.0000 - root_mean_squared_error: 33690.7500\n",
            "Epoch 240/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1268593280.0000 - root_mean_squared_error: 35617.3164\n",
            "Epoch 241/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1104271744.0000 - root_mean_squared_error: 33230.5859\n",
            "Epoch 242/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1152525568.0000 - root_mean_squared_error: 33948.8672\n",
            "Epoch 243/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1083800064.0000 - root_mean_squared_error: 32921.1172\n",
            "Epoch 244/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1109835136.0000 - root_mean_squared_error: 33314.1875\n",
            "Epoch 245/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1187621376.0000 - root_mean_squared_error: 34461.8828\n",
            "Epoch 246/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1124643712.0000 - root_mean_squared_error: 33535.7070\n",
            "Epoch 247/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1217162112.0000 - root_mean_squared_error: 34887.8516\n",
            "Epoch 248/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1095476608.0000 - root_mean_squared_error: 33097.9844\n",
            "Epoch 249/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1138329216.0000 - root_mean_squared_error: 33739.1367\n",
            "Epoch 250/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1133328384.0000 - root_mean_squared_error: 33664.9414\n",
            "Epoch 251/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1110281216.0000 - root_mean_squared_error: 33320.8828\n",
            "Epoch 252/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1112981760.0000 - root_mean_squared_error: 33361.3789\n",
            "Epoch 253/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1088249728.0000 - root_mean_squared_error: 32988.6289\n",
            "Epoch 254/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1275957120.0000 - root_mean_squared_error: 35720.5430\n",
            "Epoch 255/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1163197312.0000 - root_mean_squared_error: 34105.6797\n",
            "Epoch 256/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1208037888.0000 - root_mean_squared_error: 34756.8398\n",
            "Epoch 257/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1049241216.0000 - root_mean_squared_error: 32391.9922\n",
            "Epoch 258/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1166210816.0000 - root_mean_squared_error: 34149.8281\n",
            "Epoch 259/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1122855808.0000 - root_mean_squared_error: 33509.0391\n",
            "Epoch 260/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1142542208.0000 - root_mean_squared_error: 33801.5117\n",
            "Epoch 261/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1156461056.0000 - root_mean_squared_error: 34006.7812\n",
            "Epoch 262/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1249692160.0000 - root_mean_squared_error: 35350.9844\n",
            "Epoch 263/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 973458624.0000 - root_mean_squared_error: 31200.2988\n",
            "Epoch 264/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1230405248.0000 - root_mean_squared_error: 35077.1328\n",
            "Epoch 265/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1108657408.0000 - root_mean_squared_error: 33296.5078\n",
            "Epoch 266/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1189533824.0000 - root_mean_squared_error: 34489.6211\n",
            "Epoch 267/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1098155008.0000 - root_mean_squared_error: 33138.4219\n",
            "Epoch 268/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1239222912.0000 - root_mean_squared_error: 35202.5977\n",
            "Epoch 269/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1169409536.0000 - root_mean_squared_error: 34196.6289\n",
            "Epoch 270/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1243437056.0000 - root_mean_squared_error: 35262.4023\n",
            "Epoch 271/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1223014272.0000 - root_mean_squared_error: 34971.6211\n",
            "Epoch 272/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1150291456.0000 - root_mean_squared_error: 33915.9453\n",
            "Epoch 273/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1153357056.0000 - root_mean_squared_error: 33961.1094\n",
            "Epoch 274/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1207365248.0000 - root_mean_squared_error: 34747.1602\n",
            "Epoch 275/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1091150592.0000 - root_mean_squared_error: 33032.5664\n",
            "Epoch 276/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1195822208.0000 - root_mean_squared_error: 34580.6602\n",
            "Epoch 277/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1231434752.0000 - root_mean_squared_error: 35091.8047\n",
            "Epoch 278/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1267600256.0000 - root_mean_squared_error: 35603.3750\n",
            "Epoch 279/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1112378880.0000 - root_mean_squared_error: 33352.3438\n",
            "Epoch 280/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1181577856.0000 - root_mean_squared_error: 34374.0859\n",
            "Epoch 281/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1203219200.0000 - root_mean_squared_error: 34687.4492\n",
            "Epoch 282/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1207906432.0000 - root_mean_squared_error: 34754.9492\n",
            "Epoch 283/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1236794624.0000 - root_mean_squared_error: 35168.0898\n",
            "Epoch 284/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1071009152.0000 - root_mean_squared_error: 32726.2754\n",
            "Epoch 285/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1092542592.0000 - root_mean_squared_error: 33053.6328\n",
            "Epoch 286/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1259321600.0000 - root_mean_squared_error: 35486.9219\n",
            "Epoch 287/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1132472832.0000 - root_mean_squared_error: 33652.2344\n",
            "Epoch 288/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1143113088.0000 - root_mean_squared_error: 33809.9531\n",
            "Epoch 289/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1084247168.0000 - root_mean_squared_error: 32927.9062\n",
            "Epoch 290/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1201075968.0000 - root_mean_squared_error: 34656.5430\n",
            "Epoch 291/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1217264128.0000 - root_mean_squared_error: 34889.3125\n",
            "Epoch 292/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1167964160.0000 - root_mean_squared_error: 34175.4922\n",
            "Epoch 293/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1167213696.0000 - root_mean_squared_error: 34164.5078\n",
            "Epoch 294/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1106032256.0000 - root_mean_squared_error: 33257.0625\n",
            "Epoch 295/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1090430592.0000 - root_mean_squared_error: 33021.6680\n",
            "Epoch 296/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1144301056.0000 - root_mean_squared_error: 33827.5195\n",
            "Epoch 297/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1064776320.0000 - root_mean_squared_error: 32630.9102\n",
            "Epoch 298/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1059933312.0000 - root_mean_squared_error: 32556.6172\n",
            "Epoch 299/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1121157632.0000 - root_mean_squared_error: 33483.6914\n",
            "Epoch 300/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1121027072.0000 - root_mean_squared_error: 33481.7422\n",
            "Epoch 301/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1194183040.0000 - root_mean_squared_error: 34556.9531\n",
            "Epoch 302/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1252575104.0000 - root_mean_squared_error: 35391.7383\n",
            "Epoch 303/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1295496704.0000 - root_mean_squared_error: 35993.0078\n",
            "Epoch 304/400\n",
            "46/46 [==============================] - 1s 24ms/step - loss: 1341989760.0000 - root_mean_squared_error: 36633.1797\n",
            "Epoch 305/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1206969728.0000 - root_mean_squared_error: 34741.4688\n",
            "Epoch 306/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1141045632.0000 - root_mean_squared_error: 33779.3672\n",
            "Epoch 307/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1155504384.0000 - root_mean_squared_error: 33992.7109\n",
            "Epoch 308/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1081715584.0000 - root_mean_squared_error: 32889.4453\n",
            "Epoch 309/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1103308928.0000 - root_mean_squared_error: 33216.0938\n",
            "Epoch 310/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1218424704.0000 - root_mean_squared_error: 34905.9414\n",
            "Epoch 311/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1189804416.0000 - root_mean_squared_error: 34493.5430\n",
            "Epoch 312/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1199667328.0000 - root_mean_squared_error: 34636.2148\n",
            "Epoch 313/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1204498176.0000 - root_mean_squared_error: 34705.8828\n",
            "Epoch 314/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1104361216.0000 - root_mean_squared_error: 33231.9297\n",
            "Epoch 315/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1091793792.0000 - root_mean_squared_error: 33042.3008\n",
            "Epoch 316/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1134005376.0000 - root_mean_squared_error: 33674.9961\n",
            "Epoch 317/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1175584896.0000 - root_mean_squared_error: 34286.8008\n",
            "Epoch 318/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1085961728.0000 - root_mean_squared_error: 32953.9336\n",
            "Epoch 319/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1227537920.0000 - root_mean_squared_error: 35036.2344\n",
            "Epoch 320/400\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1066357184.0000 - root_mean_squared_error: 32655.1250\n",
            "Epoch 321/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1060022208.0000 - root_mean_squared_error: 32557.9824\n",
            "Epoch 322/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1142945280.0000 - root_mean_squared_error: 33807.4727\n",
            "Epoch 323/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1041208064.0000 - root_mean_squared_error: 32267.7559\n",
            "Epoch 324/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1152915456.0000 - root_mean_squared_error: 33954.6094\n",
            "Epoch 325/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1267518976.0000 - root_mean_squared_error: 35602.2305\n",
            "Epoch 326/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1146791424.0000 - root_mean_squared_error: 33864.3086\n",
            "Epoch 327/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1200403200.0000 - root_mean_squared_error: 34646.8359\n",
            "Epoch 328/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1270884736.0000 - root_mean_squared_error: 35649.4688\n",
            "Epoch 329/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1305700864.0000 - root_mean_squared_error: 36134.4844\n",
            "Epoch 330/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1188584448.0000 - root_mean_squared_error: 34475.8555\n",
            "Epoch 331/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1214816000.0000 - root_mean_squared_error: 34854.2109\n",
            "Epoch 332/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1104767616.0000 - root_mean_squared_error: 33238.0469\n",
            "Epoch 333/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1211304064.0000 - root_mean_squared_error: 34803.7930\n",
            "Epoch 334/400\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1069454336.0000 - root_mean_squared_error: 32702.5117\n",
            "Epoch 335/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1123747072.0000 - root_mean_squared_error: 33522.3359\n",
            "Epoch 336/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1081428352.0000 - root_mean_squared_error: 32885.0781\n",
            "Epoch 337/400\n",
            "46/46 [==============================] - 1s 20ms/step - loss: 1210826496.0000 - root_mean_squared_error: 34796.9297\n",
            "Epoch 338/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1143985792.0000 - root_mean_squared_error: 33822.8594\n",
            "Epoch 339/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1164852096.0000 - root_mean_squared_error: 34129.9297\n",
            "Epoch 340/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1139646208.0000 - root_mean_squared_error: 33758.6484\n",
            "Epoch 341/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1116690560.0000 - root_mean_squared_error: 33416.9180\n",
            "Epoch 342/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1219134720.0000 - root_mean_squared_error: 34916.1094\n",
            "Epoch 343/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1214804480.0000 - root_mean_squared_error: 34854.0430\n",
            "Epoch 344/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1163677568.0000 - root_mean_squared_error: 34112.7188\n",
            "Epoch 345/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1235734400.0000 - root_mean_squared_error: 35153.0117\n",
            "Epoch 346/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1151018752.0000 - root_mean_squared_error: 33926.6680\n",
            "Epoch 347/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1142878464.0000 - root_mean_squared_error: 33806.4844\n",
            "Epoch 348/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1074210688.0000 - root_mean_squared_error: 32775.1523\n",
            "Epoch 349/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1127883776.0000 - root_mean_squared_error: 33583.9805\n",
            "Epoch 350/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1045648448.0000 - root_mean_squared_error: 32336.4883\n",
            "Epoch 351/400\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 1209471104.0000 - root_mean_squared_error: 34777.4492\n",
            "Epoch 352/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1105873792.0000 - root_mean_squared_error: 33254.6797\n",
            "Epoch 353/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1168485888.0000 - root_mean_squared_error: 34183.1211\n",
            "Epoch 354/400\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1115869568.0000 - root_mean_squared_error: 33404.6328\n",
            "Epoch 355/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1242161024.0000 - root_mean_squared_error: 35244.3047\n",
            "Epoch 356/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1159295360.0000 - root_mean_squared_error: 34048.4258\n",
            "Epoch 357/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1068549376.0000 - root_mean_squared_error: 32688.6738\n",
            "Epoch 358/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1037891904.0000 - root_mean_squared_error: 32216.3301\n",
            "Epoch 359/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1076846336.0000 - root_mean_squared_error: 32815.3359\n",
            "Epoch 360/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1246333184.0000 - root_mean_squared_error: 35303.4453\n",
            "Epoch 361/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1167471104.0000 - root_mean_squared_error: 34168.2773\n",
            "Epoch 362/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1187348864.0000 - root_mean_squared_error: 34457.9297\n",
            "Epoch 363/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1111361408.0000 - root_mean_squared_error: 33337.0859\n",
            "Epoch 364/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1099637248.0000 - root_mean_squared_error: 33160.7773\n",
            "Epoch 365/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1168284416.0000 - root_mean_squared_error: 34180.1758\n",
            "Epoch 366/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1155779840.0000 - root_mean_squared_error: 33996.7617\n",
            "Epoch 367/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1082291840.0000 - root_mean_squared_error: 32898.2031\n",
            "Epoch 368/400\n",
            "46/46 [==============================] - 1s 21ms/step - loss: 1024308224.0000 - root_mean_squared_error: 32004.8145\n",
            "Epoch 369/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1299901568.0000 - root_mean_squared_error: 36054.1484\n",
            "Epoch 370/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1147428224.0000 - root_mean_squared_error: 33873.7070\n",
            "Epoch 371/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1195115520.0000 - root_mean_squared_error: 34570.4414\n",
            "Epoch 372/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1208167168.0000 - root_mean_squared_error: 34758.6992\n",
            "Epoch 373/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1108178432.0000 - root_mean_squared_error: 33289.3125\n",
            "Epoch 374/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1157682304.0000 - root_mean_squared_error: 34024.7305\n",
            "Epoch 375/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1203644288.0000 - root_mean_squared_error: 34693.5781\n",
            "Epoch 376/400\n",
            "46/46 [==============================] - 1s 14ms/step - loss: 1035964800.0000 - root_mean_squared_error: 32186.4062\n",
            "Epoch 377/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1108194048.0000 - root_mean_squared_error: 33289.5469\n",
            "Epoch 378/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1093096448.0000 - root_mean_squared_error: 33062.0078\n",
            "Epoch 379/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1163937536.0000 - root_mean_squared_error: 34116.5273\n",
            "Epoch 380/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1049495552.0000 - root_mean_squared_error: 32395.9180\n",
            "Epoch 381/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1052590144.0000 - root_mean_squared_error: 32443.6445\n",
            "Epoch 382/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1043930240.0000 - root_mean_squared_error: 32309.9082\n",
            "Epoch 383/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1049976768.0000 - root_mean_squared_error: 32403.3438\n",
            "Epoch 384/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1155490176.0000 - root_mean_squared_error: 33992.5039\n",
            "Epoch 385/400\n",
            "46/46 [==============================] - 1s 22ms/step - loss: 1209745152.0000 - root_mean_squared_error: 34781.3906\n",
            "Epoch 386/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1060938496.0000 - root_mean_squared_error: 32572.0508\n",
            "Epoch 387/400\n",
            "46/46 [==============================] - 1s 23ms/step - loss: 1274571392.0000 - root_mean_squared_error: 35701.1406\n",
            "Epoch 388/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1113098496.0000 - root_mean_squared_error: 33363.1289\n",
            "Epoch 389/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1020275840.0000 - root_mean_squared_error: 31941.7559\n",
            "Epoch 390/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1006107712.0000 - root_mean_squared_error: 31719.2012\n",
            "Epoch 391/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1172917760.0000 - root_mean_squared_error: 34247.8867\n",
            "Epoch 392/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1119853568.0000 - root_mean_squared_error: 33464.2148\n",
            "Epoch 393/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1112281088.0000 - root_mean_squared_error: 33350.8789\n",
            "Epoch 394/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1222195200.0000 - root_mean_squared_error: 34959.9102\n",
            "Epoch 395/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1209929984.0000 - root_mean_squared_error: 34784.0469\n",
            "Epoch 396/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1133414016.0000 - root_mean_squared_error: 33666.2148\n",
            "Epoch 397/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1077971968.0000 - root_mean_squared_error: 32832.4805\n",
            "Epoch 398/400\n",
            "46/46 [==============================] - 1s 16ms/step - loss: 1005192448.0000 - root_mean_squared_error: 31704.7695\n",
            "Epoch 399/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1095307392.0000 - root_mean_squared_error: 33095.4258\n",
            "Epoch 400/400\n",
            "46/46 [==============================] - 1s 15ms/step - loss: 1218469888.0000 - root_mean_squared_error: 34906.5859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7978777e0640>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([num_train_data] + cat_train_2, train_labels.to_numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A2l1AKTgnm4",
        "outputId": "d1781990-828e-4cb9-9189-22d8dbd96d6e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 13ms/step - loss: 307472096.0000 - root_mean_squared_error: 17534.8809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[307472096.0, 17534.880859375]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Machine Learning Model on test data.**"
      ],
      "metadata": {
        "id": "Hpkztte2AzjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataframe = reading_housing_data(directory = os.path.join(HOUSING_DATASET_DIRECTORY, \"test.csv\"))\n",
        "test_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "tnmlFHVkAgg2",
        "outputId": "12f82097-802f-4960-a5b0-f9587f1cbca8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
              "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
              "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
              "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
              "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
              "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
              "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
              "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
              "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
              "...          ...       ...  ...         ...      ...    ...    ...   \n",
              "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
              "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
              "\n",
              "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0            NaN       0      6    2010        WD         Normal  \n",
              "1           Gar2   12500      6    2010        WD         Normal  \n",
              "2            NaN       0      3    2010        WD         Normal  \n",
              "3            NaN       0      6    2010        WD         Normal  \n",
              "4            NaN       0      1    2010        WD         Normal  \n",
              "...          ...     ...    ...     ...       ...            ...  \n",
              "1454         NaN       0      6    2006        WD         Normal  \n",
              "1455         NaN       0      4    2006        WD        Abnorml  \n",
              "1456         NaN       0      9    2006        WD        Abnorml  \n",
              "1457        Shed     700      7    2006        WD         Normal  \n",
              "1458         NaN       0     11    2006        WD         Normal  \n",
              "\n",
              "[1459 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2bed348-d3ec-41a7-b4c9-d436e7beb884\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>2915</td>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1936</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>2916</td>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2917</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>160.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2918</td>\n",
              "      <td>85</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10441</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>700</td>\n",
              "      <td>7</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2919</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>9627</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2bed348-d3ec-41a7-b4c9-d436e7beb884')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2bed348-d3ec-41a7-b4c9-d436e7beb884 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2bed348-d3ec-41a7-b4c9-d436e7beb884');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c84b032d-161f-4d39-8b61-228f59a427ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c84b032d-161f-4d39-8b61-228f59a427ad')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c84b032d-161f-4d39-8b61-228f59a427ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_test_dataframe = Drop_Column().fit_transform(test_dataframe)\n",
        "dropped_test_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NMClZ7clAygM",
        "outputId": "731baff9-9639-4c55-b6b9-05d4c5683430"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0             20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1             20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2             60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3             60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4            120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "...          ...      ...          ...      ...    ...   ...      ...   \n",
              "1454         160       RM         21.0     1936   Pave   NaN      Reg   \n",
              "1455         160       RM         21.0     1894   Pave   NaN      Reg   \n",
              "1456          20       RL        160.0    20000   Pave   NaN      Reg   \n",
              "1457          85       RL         62.0    10441   Pave   NaN      Reg   \n",
              "1458          60       RL         74.0     9627   Pave   NaN      Reg   \n",
              "\n",
              "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
              "0            Lvl    AllPub    Inside  ...         120        0    NaN  MnPrv   \n",
              "1            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
              "2            Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
              "3            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
              "4            HLS    AllPub    Inside  ...         144        0    NaN    NaN   \n",
              "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
              "1454         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
              "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
              "1456         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
              "1457         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
              "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
              "\n",
              "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
              "0            NaN       0       6    2010        WD         Normal  \n",
              "1           Gar2   12500       6    2010        WD         Normal  \n",
              "2            NaN       0       3    2010        WD         Normal  \n",
              "3            NaN       0       6    2010        WD         Normal  \n",
              "4            NaN       0       1    2010        WD         Normal  \n",
              "...          ...     ...     ...     ...       ...            ...  \n",
              "1454         NaN       0       6    2006        WD         Normal  \n",
              "1455         NaN       0       4    2006        WD        Abnorml  \n",
              "1456         NaN       0       9    2006        WD        Abnorml  \n",
              "1457        Shed     700       7    2006        WD         Normal  \n",
              "1458         NaN       0      11    2006        WD         Normal  \n",
              "\n",
              "[1459 rows x 79 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9efbba31-803a-484e-be7f-9a79074ac73c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1936</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>160</td>\n",
              "      <td>RM</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1894</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>160.0</td>\n",
              "      <td>20000</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>85</td>\n",
              "      <td>RL</td>\n",
              "      <td>62.0</td>\n",
              "      <td>10441</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>Shed</td>\n",
              "      <td>700</td>\n",
              "      <td>7</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>9627</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1459 rows × 79 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9efbba31-803a-484e-be7f-9a79074ac73c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9efbba31-803a-484e-be7f-9a79074ac73c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9efbba31-803a-484e-be7f-9a79074ac73c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b12851-14cf-4be8-adc9-702d0aec38e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b12851-14cf-4be8-adc9-702d0aec38e0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b12851-14cf-4be8-adc9-702d0aec38e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test, cat_test = return_numerical_and_categorical_subset(dropped_test_dataframe)\n",
        "\n",
        "cat_test_1 = np.hsplit(cat_test, 43)"
      ],
      "metadata": {
        "id": "2N9sXyezBR5v"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting prediction for test dataset and write the prediction into a csv file.**"
      ],
      "metadata": {
        "id": "_weJ-H7zo_lH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = model.predict([num_test] + cat_test_1)\n",
        "test_prediction = tf.squeeze(test_prediction, axis = 1)\n",
        "print(test_prediction.shape)\n",
        "\n",
        "saved_prediction_results_to_csv(test_dataframe, test_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZH8FpdvCMWw",
        "outputId": "01ff7abb-9adf-43b1-aa5f-f1cf857f2720"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 12ms/step\n",
            "(1459,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npd0pKXJDN6h",
        "outputId": "b9176e81-dd8a-4e1b-8d2c-3cd93f58d4d8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXt4BDzmVM9lK1ufwiCOPm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}